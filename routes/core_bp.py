from flask import Blueprint, render_template_string, request, jsonify, send_file, render_template, redirect, url_for, send_from_directory, session
import requests
import os
from shared import login_required, is_safe_url, BASE_DIR, DL_DIR
import managers
from spider_core import crawler_instance as crawler, searcher, epub_handler, parse_chapter_id
import re
core_bp = Blueprint('core', __name__)
DEFAULT_SERVER = 'https://auth.ztrztr.top'
DEFAULT_CALLBACK = 'https://book.ztrztr.top/callback'
# æ³¨æ„ï¼šCLIENT_ID å’Œ SECRET é€šå¸¸ä¸å»ºè®®ç¡¬ç¼–ç é»˜è®¤å€¼ï¼Œ
# ä½†ä¸ºäº†é…åˆä½ çš„é€»è¾‘ï¼Œå¦‚æœ .env æ²¡å¡«ï¼Œè¿™é‡Œå¯ä»¥ç•™ç©ºæˆ–è€…å†™æ­»ä½ çš„å¤‡ç”¨ Key
DEFAULT_CLIENT_ID = None 
DEFAULT_CLIENT_SECRET = None
CLIENT_ID = os.environ.get('CLIENT_ID') or DEFAULT_CLIENT_ID
CLIENT_SECRET = os.environ.get('CLIENT_SECRET') or DEFAULT_CLIENT_SECRET
AUTH_SERVER = os.environ.get('SERVER', 'https://auth.ztrztr.top')
REDIRECT_URI = os.environ.get('CALLBACK', 'https://book.ztrztr.top/callback')
def calculate_real_chapter_id(book_key, chapter_url, chapter_title):
    """
    åªé€šè¿‡æ ‡é¢˜è¯†åˆ«çœŸå®åºå·ã€‚
    å¦‚æœè¯†åˆ«ä¸åˆ°ï¼Œè¿”å› -1ï¼Œä¸å†å°è¯•ä» URL ççŒœã€‚
    """
    if chapter_url.startswith('epub:'):
        return -1
    # ç­–ç•¥ A: æ ‡é¢˜è§£æ (ä½¿ç”¨æˆ‘ä»¬åˆšåˆšä¿®å¥½çš„å¢å¼ºç‰ˆå‡½æ•°)
    title_id = parse_chapter_id(chapter_title)
    if title_id > 0:
        return title_id
    
    # ç­–ç•¥ B: ä¸¥æ ¼æ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬ä¸å†ä» URL æ­£åˆ™æå– IDï¼Œ
    # å› ä¸º URL ID å¾€å¾€æ˜¯ç½‘ç«™æ•°æ®åº“çš„ ID (å¦‚ 5882.html)ï¼Œè€Œä¸æ˜¯ç¬¬å‡ ç« ã€‚
    # å¦‚æœä½ ç¡®å®šæŸäº›ç½‘ç«™ URL å°±æ˜¯ç« èŠ‚å·ï¼Œå¯ä»¥ä¿ç•™ï¼Œä½†ç›®å‰ä¸ºäº†é˜²è¯¯æŠ¥ï¼Œå»ºè®®å…³é—­ã€‚
    
    return -1
@core_bp.route('/login')
def login(): return redirect(f"{AUTH_SERVER}/oauth/authorize?client_id={CLIENT_ID}&redirect_uri={REDIRECT_URI}")

@core_bp.route('/callback')
def callback():
    code = request.args.get('code')
    try:
        resp = requests.post(f"{AUTH_SERVER}/oauth/token", json={'grant_type': 'authorization_code', 'client_id': CLIENT_ID, 'client_secret': CLIENT_SECRET, 'code': code}).json()
        if 'access_token' in resp:
            u = requests.get(f"{AUTH_SERVER}/api/user", headers={'Authorization': f"Bearer {resp['access_token']}"}).json()
            session.permanent = True
            session['user'] = u
            return redirect(url_for('core.index'))
    except: pass
    return "Login Failed", 400

@core_bp.route('/logout')
def logout(): session.clear(); return redirect('/')
from spider_core import parse_chapter_id
# [æ–°å¢] è§£æé¡µç çš„è¾…åŠ©å‡½æ•°
def get_page_index(url):
    """ä» URL è§£æé¡µç  (ä¾‹å¦‚ 123_2.html -> 2, 123.html -> 1)"""
    try:
        # åŒ¹é… _2.html è¿™ç§æ ¼å¼
        match = re.search(r'_(\d+)\.', url)
        if match:
            return int(match.group(1))
    except: pass
    return 1 # é»˜è®¤æ˜¯ç¬¬ 1 é¡µ
# routes/core_bp.py

from flask import make_response # è®°å¾—å¼•å…¥è¿™ä¸ª

@core_bp.route('/api/me')
def api_me():
    # 1. è·å– Session ä¸­çš„åŸºç¡€ä¿¡æ¯
    user = session.get('user', {"username": None})
    
    # 2. ã€æ ¸å¿ƒã€‘å®æ—¶æŸ¥è¯¢å¹¶æ³¨å…¥è§’è‰²æƒé™
    # å³ä½¿ Session é‡Œæ²¡å­˜ roleï¼Œè¿™é‡Œä¹Ÿè¦æŸ¥å‡ºæ¥å¡è¿›å»
    if user.get('username'):
        # è¿™é‡Œçš„ managers.role_manager éœ€è¦ç¡®ä¿å·²å¯¼å…¥
        user['role'] = managers.role_manager.get_role(user['username'])
    
    # 3. ã€æ ¸å¿ƒã€‘æ„å»ºå“åº”å¹¶ç¦æ­¢ç¼“å­˜
    response = make_response(jsonify(user))
    # å‘Šè¯‰æµè§ˆå™¨å’Œ CDNï¼šä¸è¦ç¼“å­˜è¿™ä¸ªè¯·æ±‚ï¼
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    
    return response

@core_bp.route('/')
@login_required
def index():
    # æ—§ä»£ç : return send_file(os.path.join(BASE_DIR, 'index.html'))
    
    # === [æ–°ä»£ç ] è¯»å–æ–‡ä»¶å¹¶å½“åšæ¨¡æ¿æ¸²æŸ“ ===
    try:
        # index_path = os.path.join(BASE_DIR, 'index.html')
        # with open(index_path, 'r', encoding='utf-8') as f:
        #     html_content = f.read()
        
        # è¿™é‡Œçš„ render_template_string ä¼šè‡ªåŠ¨æ¥æ”¶ context_processor æ³¨å…¥çš„ app_version
        return render_template("index.html", 
        api_url="", app_version="1.1.3")
    except Exception as e:
        return f"Error loading index: {str(e)}", 500

@core_bp.route('/read')
@login_required
def read_mode():
    u, k = request.args.get('url'), request.args.get('key', '')
    force = request.args.get('force')
    
    # 1. å®‰å…¨æ£€æŸ¥
    if not u.startswith('epub:') and not is_safe_url(u): 
        return "Illegal URL", 403
    
    data = None
    
    # 2. è·å–æ•°æ® (æ”¾åœ¨ try å—ä¸­åªè´Ÿè´£è·å–)
    try:
        if u.startswith('epub:'):
            # EPUB é€»è¾‘
            parts = u.split(':')
            filename = parts[1]
            
            if len(parts) >= 3 and parts[2] == 'toc':
                return redirect(url_for('core.toc_page', url=u, key=k))
            
            if len(parts) >= 4:
                identifier = parts[2]
                page_index = int(parts[3])
            else:
                identifier = parts[2]
                page_index = 0
            
            data = epub_handler.get_chapter_content(filename, identifier, page_index)
        else:
            # ç½‘é¡µé€»è¾‘
            data = managers.offline_manager.get_chapter(k, u) if k and not force else None
            if not data and not force: data = managers.cache.get(u)
            if not data:
                data = crawler.run(u)
                if data: managers.cache.set(u, data)

    except Exception as e:
        # æ•è·çˆ¬è™«å†…éƒ¨çš„é”™è¯¯
        print(f"[Read Error] {e}")
        return f"è§£æå‘ç”Ÿé”™è¯¯: {str(e)}", 500

    # 3. [æ ¸å¿ƒä¿®å¤] å¿…é¡»å…ˆåˆ¤æ–­ data æ˜¯å¦å­˜åœ¨
    if not data:
        return render_template_string("""
            <div style="text-align:center; padding:50px;">
                <h3>æ— æ³•è·å–ç« èŠ‚å†…å®¹</h3>
                <p>å¯èƒ½æ˜¯æºç«™è¿æ¥è¶…æ—¶ï¼Œæˆ–è¯¥ç« èŠ‚éœ€è¦ä»˜è´¹/ç™»å½•ã€‚</p>
                <a href="javascript:history.back()">è¿”å›</a>
            </div>
        """), 404

    # 4. åç»­å¤„ç† (æ­¤æ—¶ data ä¸€å®šä¸ä¸º Noneï¼Œå¯ä»¥å®‰å…¨è°ƒç”¨ .get)
    try:
        # è®°å½•å†å²
        if k and data.get('title'):
            managers.history_manager.add_record(k, data['title'], u, data.get('book_name'))

        # è®¡ç®— ID
        current_chapter_id = -1
        if data.get('title'):
            current_chapter_id = parse_chapter_id(data['title'])
        
        # ç½‘é¡µç‰ˆ URL å…œåº• ID
        if current_chapter_id <= 0 and not u.startswith('epub:'):
            match = re.search(r'/(\d+)(?:_\d+)?(?:\.html)?$', u.split('?')[0])
            if match: current_chapter_id = int(match.group(1))

        # 5. æ¸²æŸ“é¡µé¢
        ua = request.headers.get('User-Agent', '').lower()
        is_mobile = any(x in ua for x in ['iphone', 'android', 'phone', 'mobile'])
        
        context = {
            'article': data,
            'current_url': u,
            'db_key': k,
            'chapter_id': current_chapter_id
        }

        if is_mobile:
            return render_template('reader_m.html', **context)
        else:
            return render_template('reader_pc.html', **context)
            
    except Exception as e:
        print(f"[Render Error] {e}")
        return f"æ¸²æŸ“é”™è¯¯: {str(e)}", 500
@core_bp.route('/api/history/list')
@login_required
def api_history_list():
    return jsonify({"status": "success", "data": managers.history_manager.get_history()})

@core_bp.route('/api/history/clear', methods=['POST'])
@login_required
def api_history_clear():
    managers.history_manager.clear()
    return jsonify({"status": "success"})
@core_bp.route('/toc')
@login_required
def toc_page():
    u, k = request.args.get('url'), request.args.get('key', '')
    # æ¥æ”¶ force å‚æ•°ï¼Œå¦‚æœæ˜¯ 'true' åˆ™è·³è¿‡ç¼“å­˜
    force = request.args.get('force') == 'true'
    is_api = request.args.get('api')
    if u.startswith('epub:'):
        # åè®®æ ¼å¼ï¼šepub:æ–‡ä»¶å:ç´¢å¼• (ä¾‹å¦‚ epub:test.epub:toc)
        parts = u.split(':')
        filename = parts[1]
        data = epub_handler.get_toc(filename)
        
        if not data:
            return "EPUB ç›®å½•è§£æå¤±è´¥", 404
            
        if is_api:
            return jsonify(data)
        return render_template('toc.html', toc=data, toc_url=u, db_key=k)
    data = None
    
    # ç½‘é¡µé€»è¾‘
    # å¦‚æœ force ä¸º trueï¼Œå…ˆä¸è¯»ç¼“å­˜ï¼Œä¹Ÿåˆ«è®© crawler è¯»ç¼“å­˜
    # ä½†ç”±äºæˆ‘ä»¬åœ¨ crawler.run é‡Œå¼ºåˆ¶åŠ äº†è¯»ç¼“å­˜é€»è¾‘ï¼Œè¿™é‡Œéœ€è¦ä¸€ç‚¹æŠ€å·§ï¼š
    
    # æ–¹æ¡ˆ A: ç›¸ä¿¡ crawler.run çš„ç¼“å­˜æœºåˆ¶ (æ¨è)
    # æˆ‘ä»¬éœ€è¦è®© crawler.run çŸ¥é“æˆ‘ä»¬è¦å¼ºåˆ¶åˆ·æ–°ã€‚
    # ä½†è¿™éœ€è¦æ”¹åŠ¨ crawler.run çš„ç­¾åã€‚
    
    # æ–¹æ¡ˆ B (å½“å‰ä»£ç ç°çŠ¶):
    # æ—¢ç„¶æˆ‘ä»¬åœ¨ crawler.run é‡ŒåŠ äº†ç¼“å­˜æ£€æŸ¥ï¼Œé‚£ä¹ˆ routes é‡Œçš„ managers.cache.get(u) å°±å¯ä»¥åˆ æ‰äº†ï¼Ÿ
    # ä¸å®Œå…¨æ˜¯ã€‚ä¸ºäº†å…¼å®¹æ€§ï¼Œæˆ‘ä»¬ä¿ç•™ routes é‡Œçš„é€»è¾‘ã€‚
    
    # [å…³é”®]ï¼šå¦‚æœä½ æƒ³è®©â€œå¼ºåˆ¶åˆ·æ–°â€ç”Ÿæ•ˆï¼Œä½ éœ€è¦åœ¨ crawler.run ä¹‹å‰æ‰‹åŠ¨æ¸…ç†ä¸€ä¸‹ç¼“å­˜
    if force:
        try:
            # åˆ æ‰ç¼“å­˜æ–‡ä»¶ï¼Œè¿™æ · crawler.run å†…éƒ¨ check cache å°±ä¼š missï¼Œä»è€Œå»è¿œç¨‹çˆ¬
            from managers import cache
            cache_file = cache._get_filename(u)
            if os.path.exists(cache_file):
                os.remove(cache_file)
        except: pass
    
    if not data:
        data = crawler.get_toc(u)
        print("getting data", u)
        if data:
            managers.cache.set(u, data)
    
    if is_api:
        return jsonify(data if data else {"status": "error", "message": "æ— æ³•è·å–ç›®å½•"})

    return render_template('toc.html', toc=data, toc_url=u, db_key=k)

@core_bp.route('/list', methods=['POST'])
@login_required
def list_all(): return jsonify(managers.db.list_all())

@core_bp.route('/find', methods=['POST'])
@login_required
def find(): return jsonify(managers.db.find(request.json.get('key', '')))

@core_bp.route('/insert', methods=['POST'])
@login_required
def insert():
    key = request.json.get('key')
    raw_value = request.json.get('value') # åŸå§‹è¾“å…¥
    is_manual = request.json.get('manual', False)
    
    # [æ ¸å¿ƒä¿®æ”¹] æ™ºèƒ½çº é”™
    # åªæœ‰åœ¨æ‰‹åŠ¨è¾“å…¥æ—¶æ‰å°è¯•çº é”™ï¼Œè‡ªåŠ¨åŒæ­¥æ—¶ä¸çº é”™(èŠ‚çœæ€§èƒ½)
    # final_value = raw_value
    # if is_manual:
        # è°ƒç”¨çˆ¬è™«çš„æ™ºèƒ½è§£æ
        # final_value = crawler.resolve_start_url(raw_value)
    
    # ä¿å­˜çº é”™åçš„å€¼
    final_value = raw_value
    res = managers.db.insert(key, final_value)
    if is_manual and res.get('status') == 'success':
        managers.db.add_version(key, final_value)
        
    return jsonify(res)

import time
@core_bp.route('/update', methods=['POST'])
@login_required
def update():
    key = request.json.get('key')
    value = request.json.get('value')
    title = request.json.get('title', '') 
    is_manual = request.json.get('manual', False)

    # 1. ä¿å­˜ URL (è¿™æ˜¯åŸºç¡€ KV è®°å½•)
    final_value = value
    if is_manual and hasattr(crawler, 'resolve_start_url'):
        final_value = crawler.resolve_start_url(value)
    
    res = managers.db.update(key, final_value)

    # 2. ã€æ ¸å¿ƒä¿®æ”¹ç‚¹ã€‘è®¡ç®—å¹¶ä¿å­˜åºå·
    real_id = calculate_real_chapter_id(key, final_value, title)
    
    # åªæœ‰å½“ real_id æ˜¯æœ‰æ•ˆæ­£æ•´æ•°æ—¶æ‰æ›´æ–° meta
    # å¦‚æœè¿”å› -1 (æœªè¯†åˆ«)ï¼Œè¿™é‡Œç›´æ¥è·³è¿‡ï¼Œæ•°æ®åº“é‡Œæ—§çš„ meta ä¼šä¿ç•™
    if real_id > 0:
        try:
            import json
            # è·å–æ—§ meta
            old_meta_str = managers.db.get_val(f"{key}:meta")
            meta = json.loads(old_meta_str) if old_meta_str else {}
            
            # æ›´æ–°åºå·å’Œæ—¶é—´æˆ³
            meta['chapter_id'] = real_id
            meta['updated_at'] = int(time.time())
            
            managers.db.update(f"{key}:meta", json.dumps(meta))
            # print(f"[Sync] è¯†åˆ«æˆåŠŸï¼š{title} -> ID {real_id}")
        except Exception as e:
            print(f"[Sync] Meta save error: {e}")
    else:
        # å¦‚æœæ²¡è¯†åˆ«åˆ°ï¼Œæ‰“å°ä¸€ä¸ªæ—¥å¿—æ–¹ä¾¿è°ƒè¯•ï¼Œä½†ä¸å†™åº“
        print(f"[Sync] âš ï¸ ç« èŠ‚è¯†åˆ«å¤±è´¥ï¼Œè·³è¿‡ Meta è®°å½•: {title}")

    # 3. å†å²ç‰ˆæœ¬ (ä»…æ‰‹åŠ¨)
    if is_manual and res.get('status') == 'success':
        managers.db.add_version(key, final_value)
    
    return jsonify(res)
# routes/core_bp.py

@core_bp.route('/api/rename_key', methods=['POST'])
@login_required
def api_rename_key():
    old_key = request.json.get('old_key')
    new_key = request.json.get('new_key')
    
    if not old_key or not new_key:
        return jsonify({"status": "error", "message": "å‚æ•°ä¸è¶³"})
    
    # è°ƒç”¨åˆšæ‰åœ¨ managers é‡Œå†™çš„é€»è¾‘
    res = managers.db.rename_key(old_key, new_key)
    return jsonify(res)
@core_bp.route('/api/switch_source', methods=['POST'])
@login_required
def api_switch_source():
    current_url = request.json.get('url')
    book_key = request.json.get('key')
    
    if not current_url or not book_key:
        return jsonify({"status": "error", "msg": "Missing params"})

    try:
        # 1. è·å–å½“å‰ä¹¦å (ä»ä¹¦å•æˆ–ç¼“å­˜æ‹¿ï¼Œæˆ–è€…é‡æ–°çˆ¬å½“å‰é¡µ)
        # ä¸ºäº†å‡†ç¡®ï¼Œæˆ‘ä»¬å…ˆå°è¯•ä»ç¼“å­˜æ‹¿å½“å‰é¡µä¿¡æ¯
        book_name = ""
        current_id = -1
        
        cached_page = managers.cache.get(current_url)
        if cached_page:
            # å°è¯•ä»é¡µé¢æ ‡é¢˜æå–ä¹¦å (é€šå¸¸æ ¼å¼: ç¬¬xxç«  æ ‡é¢˜ - ä¹¦å - ç½‘ç«™å)
            # è¿™æ­¥æ¯”è¾ƒéš¾ï¼Œå¦‚æœç¼“å­˜é‡Œæ²¡å­˜ä¹¦åï¼Œæˆ‘ä»¬åªèƒ½ç”¨ SearchHelper çš„ key åæ¨æˆ–è€…è®©å‰ç«¯ä¼ 
            # ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ç”¨ key (æ‹¼éŸ³) å»ä¹¦å•é‡ŒåæŸ¥ä¹¦åï¼Œæˆ–è€…è®©ç”¨æˆ·å‰ç«¯ä¼ ä¹¦å
            pass
            
        # æ›´å¥½çš„æ–¹æ¡ˆï¼šå‰ç«¯ä¼  book_title è¿‡æ¥ã€‚
        # å¦‚æœå‰ç«¯æ²¡ä¼ ï¼Œæˆ‘ä»¬å»ä¹¦å•ç®¡ç†å™¨é‡ŒæŸ¥è¿™ä¸ª key å¯¹åº”çš„ä¹¦å
        book_name = request.json.get('title')
        if not book_name:
             # å°è¯•ä»ä¹¦å•åæŸ¥
             all_lists = managers.booklist_manager.load()
             for lid, ldata in all_lists.items():
                 for book in ldata.get('books', []):
                     if book['key'] == book_key:
                         book_name = book['title']
                         break
                 if book_name: break
        
        if not book_name:
            return jsonify({"status": "error", "msg": "æ— æ³•è·å–ä¹¦åï¼Œè¯·å…ˆå°†ä¹¦åŠ å…¥ä¹¦å•"})

        # 2. è·å–å½“å‰ç« èŠ‚ ID
        if cached_page and cached_page.get('title'):
             current_id = parse_chapter_id(cached_page['title'])
        
        if current_id <= 0:
             # å°è¯•æ­£åˆ™
             import re
             match = re.search(r'/(\d+)(?:_\d+)?(?:\.html)?$', current_url)
             if match: current_id = int(match.group(1))

        if current_id <= 0:
            return jsonify({"status": "error", "msg": "æ— æ³•è¯†åˆ«å½“å‰ç« èŠ‚ID"})

        # 3. æ‰§è¡Œæ¢æº
        result = crawler.search_and_switch_source(book_name, current_id)
        
        if result:
            # æ‰¾åˆ°æ–°æºäº†ï¼
            new_url = result['new_url']
            
            # 4. æ›´æ–°æ•°æ®åº“ (æ— ç¼è¡”æ¥)
            managers.db.update(book_key, new_url)
            
            # 5. é¡ºä¾¿æ›´æ–°ä¸‹ç¼“å­˜ (é¢„çƒ­)
            # threading.Thread(target=crawler.run, args=(new_url,)).start()
            
            return jsonify({
                "status": "success", 
                "new_url": new_url,
                "msg": f"å·²åˆ‡æ¢è‡³: {result['source_name']}"
            })
        else:
            return jsonify({"status": "failed", "msg": "å…¨ç½‘æœªæ‰¾åˆ°è¯¥ç« èŠ‚çš„å…¶ä»–æº"})

    except Exception as e:
        print(f"Switch Error: {e}")
        return jsonify({"status": "error", "msg": str(e)})
    
# @core_bp.route('/api/source/list', methods=['POST'])
# @login_required
@core_bp.route('/api/source/list', methods=['POST'])
@login_required
def api_source_list():
    current_url = request.json.get('url')
    book_key = request.json.get('key')
    frontend_title = request.json.get('title', '') # ç« èŠ‚æ ‡é¢˜
    
    if not current_url: return jsonify({"status": "error", "msg": "å‚æ•°é”™è¯¯"})

    # === æ ¸å¿ƒé€»è¾‘ï¼šå¤šçº§æ¢æµ‹çœŸå®ä¹¦å ===
    book_name = None
    
    # 1. å°è¯•ä»ä¹¦å•åæŸ¥ (ç”¨æˆ·å®šä¹‰çš„æ ‡é¢˜æœ€ä¼˜å…ˆ)
    all_lists = managers.booklist_manager.load()
    for list_data in all_lists.values():
        for b in list_data.get('books', []):
            if b['key'] == book_key:
                book_name = b['title']
                break
        if book_name: break

    # 2. ã€å…³é”®è¡¥ä¸ã€‘å¦‚æœä¹¦å•æ²¡æ‰¾åˆ°ï¼Œç›´æ¥â€œç°åœºçˆ¬å–â€å½“å‰é˜…è¯»é¡µæå–ä¹¦å
    if not book_name or re.match(r'^[a-zA-Z0-9_]+$', book_name):
        print(f"[Switch] æ— æ³•ä»æœ¬åœ°è·å–ä¹¦åï¼Œæ­£åœ¨ç°åœºçˆ¬å–æºç«™: {current_url}")
        try:
            # ç°åœºçˆ¬å–å½“å‰é¡µé¢å†…å®¹
            # æ³¨æ„ï¼šè¿™é‡Œ run ä¼šè‡ªåŠ¨è¯†åˆ«æ˜¯èµ°æ’ä»¶è¿˜æ˜¯èµ°é€šç”¨é€»è¾‘
            temp_data = crawler.run(current_url)
            if temp_data and temp_data.get('book_name'):
                book_name = temp_data['book_name']
                print(f"[Switch] ğŸ¯ ç°åœºæŠ“å–ä¹¦åæˆåŠŸ: {book_name}")
        except Exception as e:
            print(f"[Switch] ç°åœºæŠ“å–ä¹¦åå¤±è´¥: {e}")

    # 3. æœ€ç»ˆæ ¡éªŒ
    # å¦‚æœè¿˜æ˜¯æ‹¿ä¸åˆ°ä¸­æ–‡ï¼ˆå…¨æ˜¯å­—æ¯æ•°å­—ï¼‰ï¼Œè¯´æ˜çœŸçš„æ²¡æ³•æœ
    if not book_name or re.match(r'^[a-zA-Z0-9_]+$', str(book_name)):
        return jsonify({
            "status": "error", 
            "msg": f"æ— æ³•è¯†åˆ«ä¹¦å(å½“å‰:{book_name})ã€‚å»ºè®®æ‰‹åŠ¨å°†æœ¬ä¹¦åŠ å…¥ä¹¦å•å¹¶å¡«å†™ä¸­æ–‡ä¹¦åã€‚"
        })

    # === è·å–å½“å‰ç« èŠ‚ ID ===
    current_id = parse_chapter_id(frontend_title)
    if current_id <= 0:
         match = re.search(r'/(\d+)(?:_\d+)?(?:\.html)?$', current_url)
         if match: current_id = int(match.group(1))
    
    # if current_id <= 0:
    #    return jsonify({"status": "error", "msg": "æ— æ³•è¯†åˆ«å½“å‰ç« èŠ‚ID"})

    # === æœç´¢ ===
    print(f"[Switch] å‡†å¤‡æœç´¢æ–°æºï¼Œå…³é”®è¯: {book_name}")
    # æ”¹ä¸ºç›´æ¥è¿”å›æœç´¢ç»“æœï¼Œä¸åšè€—æ—¶çš„éªŒè¯
    from spider_core import searcher
    sources = searcher.search_bing_cached(book_name)
    
    if not sources:
        return jsonify({"status": "failed", "msg": "å…¨ç½‘æœªæ‰¾åˆ°ç›¸å…³ä¹¦ç±"})
        
    return jsonify({
        "status": "success", 
        "data": sources,
        # å›ä¼ ä¸Šä¸‹æ–‡ï¼Œä¾›å‰ç«¯äºŒæ¬¡ç¡®è®¤ä½¿ç”¨
        "match_info": {
            "current_id": current_id,
            "current_title": frontend_title
        }
    })

@core_bp.route('/api/source/confirm_switch', methods=['POST'])
@login_required
def api_confirm_switch():
    data = request.json
    target_url = data.get('target_url')
    current_id = data.get('current_id', -1)
    current_title = data.get('current_title', '')
    
    if not target_url: return jsonify({"status": "error", "msg": "Target URL missing"})

    new_url = crawler.find_best_match(target_url, current_id, current_title)
    
    if new_url:
        return jsonify({"status": "success", "new_url": new_url})
    else:
        return jsonify({"status": "failed", "msg": "æ— æ³•è§£æç›®æ ‡æº"})

@core_bp.route('/api/history/versions', methods=['POST'])
@login_required
def api_history_versions():
    key = request.json.get('key')
    if not key: return jsonify({"status": "error"})
    
    versions = managers.db.get_versions(key)
    return jsonify({"status": "success", "data": versions})
@core_bp.route('/remove', methods=['POST'])
@login_required
def remove(): return jsonify(managers.db.remove(request.json.get('key')))

@core_bp.route('/rollback', methods=['POST'])
@login_required
def rollback(): return jsonify(managers.db.rollback())

@core_bp.route('/api/get_value', methods=['POST'])
@login_required
def get_val():
    key = request.json.get('key')
    v = managers.db.get_val(key)
    
    if v:
        # ç›´æ¥è¯»å– metaï¼Œä¸å†è¿›è¡Œä»»ä½•çˆ¬è™«æˆ–è§£æ
        meta_str = managers.db.get_val(f"{key}:meta")
        meta = {}
        if meta_str:
            try: 
                import json
                meta = json.loads(meta_str) 
            except: pass
        
        return jsonify({
            "status": "success", 
            "value": v,
            "meta": meta # è¿™é‡Œé¢åŒ…å«å‡†ç¡®çš„ chapter_id
        })
        
    return jsonify({"status": "error"})

@core_bp.route('/api/last_read', methods=['GET', 'POST'])
@login_required
def handle_last_read():
    if request.method == 'GET': return jsonify({"status": "success", "key": managers.db.get_val('@last_read')})
    return jsonify(managers.db.insert('@last_read', request.json.get('key')))

@core_bp.route('/api/tags/list')
@login_required
def api_tags_list(): return jsonify({"status": "success", "data": managers.tag_manager.get_all()})

@core_bp.route('/api/tags/update', methods=['POST'])
@login_required
def api_tags_update(): return jsonify({"status": "success", "tags": managers.tag_manager.update_tags(request.json.get('key'), request.json.get('tags', []))})

@core_bp.route('/api/analyze_stats')
@login_required
def api_analyze_stats(): return jsonify({"status": "success", "summary": managers.stats_manager.get_summary(), "keywords": []})

@core_bp.route('/api/stats/heartbeat', methods=['POST'])
@login_required
def api_heartbeat():
    d = request.json
    managers.stats_manager.update(60 if d.get('is_heartbeat') else 0, d.get('words', 0), 1 if d.get('words', 0)>0 else 0, d.get('book_key'))
    return jsonify({"status": "success"})

@core_bp.route('/api/booklists/all')
@login_required
def api_booklists_all(): return jsonify({"status": "success", "data": managers.booklist_manager.load()})

@core_bp.route('/api/booklists/create', methods=['POST'])
@login_required
def api_booklists_create(): return jsonify({"status": "success", "id": managers.booklist_manager.add_list(request.json.get('name'))})

@core_bp.route('/api/booklists/add_book', methods=['POST'])
@login_required
def api_booklists_add(): 
    managers.booklist_manager.add_to_list(request.json['list_id'], request.json['book_data'])
    return jsonify({"status": "success"})
@core_bp.route('/api/booklists/update_book', methods=['POST'])
@login_required
def api_booklists_update():
    d = request.json
    managers.booklist_manager.update_status(
        d.get('list_id'), 
        d.get('book_key'), 
        d.get('status'), 
        d.get('action')
    )
    # å¿…é¡»è¿”å›æœ€æ–°çš„ dataï¼Œå› ä¸ºå‰ç«¯ updateBookStatus ä¾èµ–å®ƒæ¥åˆ·æ–°é¡µé¢
    return jsonify({"status": "success", "data": managers.booklist_manager.load()})

@core_bp.route('/api/prefetch', methods=['POST'])
@login_required
def api_prefetch():
    u = request.json.get('url')
    if managers.cache.get(u): return jsonify({"status": "skipped"})
    d = crawler.run(u)
    if d:
        managers.cache.set(u, d)
        return jsonify({"status": "success"})
    return jsonify({"status": "failed"})

@core_bp.route('/api/resolve_head', methods=['POST'])
@login_required
def api_resolve_head():
    try: return jsonify({"status": "success", "url": crawler.get_first_chapter(request.json.get('url'))})
    except: return jsonify({"status": "error"})

@core_bp.route('/api/search_novel', methods=['POST'])
@login_required
def api_search(): return jsonify({"status": "success", "data": searcher.search_bing(request.json.get('keyword'))})

@core_bp.route('/api/upload_epub', methods=['POST'])
@login_required
def api_upload_epub():
    if 'file' not in request.files: return jsonify({"status": "error"})
    f = request.files['file']
    fn = epub_handler.save_file(f)
    k = searcher.get_pinyin_key(os.path.splitext(fn)[0])
    v = f"epub:{fn}:toc"
    managers.db.insert(k, v)
    return jsonify({"status": "success", "key": k, "value": v})
# ... å¼•å…¥ update_manager ...
from managers import db, update_manager, booklist_manager

# 1. æ‰‹åŠ¨æ£€æŸ¥å•æœ¬æ›´æ–°
@core_bp.route('/api/check_update', methods=['POST'])
@login_required
def api_check_update():
    # å‰ç«¯ä¼ æ¥çš„å½“å‰é˜…è¯» URL å’Œ Key
    current_url = request.json.get('url') 
    book_key = request.json.get('key')
    
    if not current_url: return jsonify({"status": "error", "msg": "No URL"})

    try:
        # === 1. æ™ºèƒ½å®šä½ç›®å½•é¡µ URL ===
        toc_url = None
        
        # ä¼˜å…ˆä»ç¼“å­˜çš„â€œå½“å‰é˜…è¯»é¡µâ€ä¿¡æ¯ä¸­æ‰¾ç›®å½•é“¾æ¥
        cached_page = managers.cache.get(current_url)
        if cached_page and cached_page.get('toc_url'): 
            toc_url = cached_page['toc_url']
        else:
            # ç¼“å­˜æœªå‘½ä¸­ç›®å½•é“¾æ¥ï¼Œå°è¯•çˆ¬å–å½“å‰é¡µè·å–
            try:
                page_data = crawler.run(current_url)
                if page_data: 
                    toc_url = page_data.get('toc_url')
                    managers.cache.set(current_url, page_data)
            except: pass

        # å…œåº•çŒœæµ‹
        if not toc_url: 
            toc_url = current_url.rsplit('/', 1)[0] + '/'

        # === 2. [æ ¸å¿ƒ] å¼ºåˆ¶æ¸…é™¤ç›®å½•ç¼“å­˜ ===
        # ç¡®ä¿è§¦å‘çˆ¬è™«è”ç½‘è·å–æœ€æ–°æ•°æ®ï¼ˆç« èŠ‚ã€å°é¢ã€æ ‡ç­¾ç­‰ï¼‰
        try:
            from managers import cache
            cache_file = cache._get_filename(toc_url)
            if os.path.exists(cache_file):
                os.remove(cache_file)
                print(f"[Update] å¼ºåˆ¶åˆ·æ–°ï¼Œå·²æ¸…ç†ç¼“å­˜: {toc_url}")
        except Exception as e:
            print(f"[Update] æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")

        # === 3. çˆ¬å–æœ€æ–°ç›®å½•å’Œå…ƒæ•°æ® ===
        toc_data = crawler.get_toc(toc_url)
        
        if toc_data and toc_data.get('chapters'):
            # è·å–æœ€æ–°ç« èŠ‚å¯¹è±¡
            latest_chap = toc_data['chapters'][-1]
            
            # === 4. æ›´æ–°æ•°æ®åº“å…ƒæ•°æ® (å°é¢/ä½œè€…/ç®€ä»‹/æ ‡ç­¾) ===
            update_payload = {}
            if toc_data.get('cover'): update_payload['cover'] = toc_data['cover']
            if toc_data.get('author'): update_payload['author'] = toc_data['author']
            if toc_data.get('desc'): update_payload['desc'] = toc_data['desc']
            # [æ–°å¢] ä¿å­˜å®˜æ–¹æ ‡ç­¾
            if toc_data.get('tags'): update_payload['official_tags'] = toc_data['tags']
            
            if update_payload:
                print(f"[Update] æ›´æ–°ä¹¦ç±å…ƒæ•°æ®: {book_key} -> {list(update_payload.keys())}")
                managers.db.update(book_key, update_payload)

            # === 5. æ›´æ–°è¿½æ›´ç®¡ç†å™¨ (UpdateManager) ===
            save_data = {
                "latest_title": latest_chap.get('title') or latest_chap.get('name'),
                "latest_url": latest_chap['url'],
                "latest_id": latest_chap.get('id', -1),
                "toc_url": toc_url
            }
            managers.update_manager.set_update(book_key, save_data)
            
            # === 6. è®¡ç®—è¿›åº¦å·®å€¼ (è¿”å›ç»™å‰ç«¯) ===
            
            # A. è·å–å½“å‰é˜…è¯»ç« èŠ‚ ID
            current_id = parse_chapter_id(current_url)
            if current_id <= 0:
                match = re.search(r'/(\d+)(?:_\d+)?(?:\.html)?$', current_url)
                if match: current_id = int(match.group(1))
            
            latest_id = save_data['latest_id']
            
            # æ„é€ è¿”å›æ•°æ®
            response_data = {
                "latest_title": save_data['latest_title'],
                "latest_url": save_data['latest_url'],
                "unread_count": 0,
                "status_text": "å·²æœ€æ–°"
            }

            # B. æ‰§è¡Œæ¯”å¯¹
            if latest_id > 0 and current_id > 0:
                diff = latest_id - current_id
                if diff > 0:
                    response_data["unread_count"] = diff
                    response_data["status_text"] = f"è½å {diff} ç« "
                else:
                    response_data["status_text"] = "å·²è¿½å¹³"
            elif current_url != save_data['latest_url']:
                response_data["unread_count"] = 1
                response_data["status_text"] = "æœ‰æ–°ç« èŠ‚"

            return jsonify({
                "status": "success", 
                "msg": "åˆ·æ–°æˆåŠŸ", 
                "data": response_data 
            })
        else:
            return jsonify({"status": "failed", "msg": "ç›®å½•è§£æå¤±è´¥"})

    except Exception as e:
        print(f"Check Update Error: {e}")
        return jsonify({"status": "error", "msg": str(e)})
# 2. è·å–æ‰€æœ‰æ›´æ–°çŠ¶æ€ (ç”¨äºå‰ç«¯æ¸²æŸ“å°çº¢ç‚¹)
from spider_core import searcher, epub_handler, parse_chapter_id 

# =========================================================
# æ ¸å¿ƒæ¥å£ï¼šè·å–æ‰€æœ‰ä¹¦çš„å®æ—¶çŠ¶æ€
# é‡æ„è¯´æ˜ï¼š
# 1. Modern Path: ä¼˜å…ˆè¯»å– update_sub_manager (SQLite),è¿™æ˜¯åå°è‡ªåŠ¨è¿½æ›´çš„ç»“æœ
# 2. Legacy Path: å¦‚æœæ²¡è®¢é˜…ï¼Œå›é€€è¯»å– update_manager (JSON),è¿™æ˜¯æ—§ç‰ˆçˆ¬è™«çš„ç»“æœ
# =========================================================

@core_bp.route('/api/updates/status', methods=['GET'])
@login_required
def api_get_updates_status():
    # --- 1. ç¡®å®šæ£€æŸ¥èŒƒå›´ ---
    # (åªæ£€æŸ¥ to_read/å¿…è¯»/è¿½æ›´ ç­‰ä¹¦å•é‡Œçš„ä¹¦ï¼Œé¿å…å…¨åº“æ‰«ææ€§èƒ½çˆ†ç‚¸)
    all_lists = managers.booklist_manager.load()
    target_books = []
    
    watch_keywords = ['to_read', 'å¿…è¯»', 'è¿½æ›´', 'reading', 'åœ¨è¯»']
    
    for list_data in all_lists.values():
        list_name = list_data.get('name', '').lower()
        if any(k in list_name for k in watch_keywords):
            target_books.extend(list_data.get('books', []))
            
    # å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šä¹¦å•ï¼Œå…œåº•æ£€æŸ¥æ‰€æœ‰æ ‡è®°ä¸º 'want' çš„ä¹¦
    if not target_books:
        for list_data in all_lists.values():
            for book in list_data.get('books', []):
                if book.get('status') == 'want':
                    target_books.append(book)

    target_keys = list(set([b['key'] for b in target_books]))
    
    # [æ ¸å¿ƒä¿®å¤] å¿…é¡»åŒ…å«æ‰€æœ‰â€œå·²æ‰‹åŠ¨è®¢é˜…â€çš„ä¹¦ï¼
    # æ— è®ºè¿™æœ¬ä¹¦åœ¨ä¸åœ¨ä¹¦å•é‡Œï¼Œåªè¦ç”¨æˆ·ç‚¹äº†â€œè¿½æ›´â€ï¼Œå°±å¿…é¡»æ£€æŸ¥
    username = session.get('user', {}).get('username')
    try:
        subscribed_keys = managers.update_sub_manager.get_all_subscribed(username)
        target_keys.extend(subscribed_keys)
        # å†æ¬¡å»é‡
        target_keys = list(set(target_keys))
        # print(f"[DEBUG] æ£€æŸ¥åˆ—è¡¨: {target_keys}")
    except Exception as e:
        print(f"[Updates] è·å–è®¢é˜…åˆ—è¡¨å¤±è´¥: {e}")

    # è·å–ç”¨æˆ·è¿›åº¦
    user_progress = managers.db.list_all().get('data', {})
    
    # é¢„åŠ è½½æ—§ç‰ˆæ•°æ® (Legacy Data Source)
    legacy_records = managers.update_manager.load()
    
    response_data = {}

    for key in target_keys:
        # === Step 1: è·å–ç”¨æˆ·å½“å‰è¿›åº¦ (Common Logic) ===
        val_obj = user_progress.get(key)
        
        # æå–å½“å‰é˜…è¯»é“¾æ¥
        current_url = ""
        if isinstance(val_obj, dict): current_url = val_obj.get('url', '')
        elif isinstance(val_obj, str): current_url = val_obj
        if not current_url: continue

        # è®¡ç®—å½“å‰ç« èŠ‚ ID (Current ID)
        current_id = -1
        # cached_page = managers.cache.get(current_url) 
        
        match = re.search(r'/(\d+)(?:_\d+)?(?:\.html)?$', current_url)
        if match: current_id = int(match.group(1))

        if current_id <= 0: continue 

        # === Step 2: è·å–æœ€æ–°ç« èŠ‚ä¿¡æ¯ (Logic Branching) ===
        latest_id = -1
        latest_title = ""
        data_source = "none" 

        # --- A. Modern Path (æ–°é€»è¾‘: SQLite) ---
        sub_status = managers.update_sub_manager.get_book_status(key)
        
        # [å…³é”®åˆ¤å®š] åªè¦ subscribed ä¸” remote_id > 0ï¼Œå°±é‡‡ä¿¡
        if sub_status and sub_status.get('subscribed') and sub_status.get('remote_id', 0) > 0:
            latest_id = sub_status['remote_id']
            latest_title = "æœ€æ–°ç« èŠ‚" 
            data_source = "modern_sql"
        
        # --- B. Legacy Path (æ—§é€»è¾‘: JSON) ---
        if latest_id <= 0:
            legacy_info = legacy_records.get(key)
            if legacy_info:
                lid = int(legacy_info.get('latest_id', -1))
                if lid <= 0 and legacy_info.get('latest_title'):
                    lid = parse_chapter_id(legacy_info['latest_title'])
                
                if lid > 0:
                    latest_id = lid
                    latest_title = legacy_info.get('latest_title', '')
                    data_source = "legacy_json"

        # === Step 3: è®¡ç®—æ›´æ–° (Payload Construction) ===
        status_payload = {
            "unread_count": 0,
            "status_text": "å·²æœ€æ–°",
            "latest_title": latest_title,
            "debug_source": data_source
        }

        if latest_id > 0:
            diff = latest_id - current_id
            if diff > 0:
                status_payload['unread_count'] = diff
                status_payload['status_text'] = f"è½å {diff} ç« "
            else:
                status_payload['status_text'] = "å·²è¿½å¹³"
        
        response_data[key] = status_payload

    return jsonify(response_data)

# =========================================================

@core_bp.route('/api/download', methods=['POST'])
@login_required
def start_dl():
    d = request.json
    toc = managers.cache.get(d['toc_url']) or crawler.get_toc(d['toc_url'])
    if not toc: return jsonify({"status": "error"})
    return jsonify({"status": "success", "task_id": managers.downloader.start_download(d['book_name'], toc['chapters'], crawler)})

@core_bp.route('/api/download/status')
@login_required
def dl_status(): return jsonify(managers.downloader.get_status(request.args.get('task_id')))

@core_bp.route('/api/download/file')
@login_required
def dl_file():
    t = managers.downloader.get_status(request.args.get('task_id'))
    return send_from_directory(DL_DIR, t['filename'], as_attachment=True) if t else ("Not Found", 404)

@core_bp.route('/manifest.json')
def serve_manifest(): return send_file('manifest.json')
@core_bp.route('/sw.js')
def serve_sw(): return send_file('sw.js')
@core_bp.route('/static/<path:filename>')
def serve_static(filename): return send_from_directory(os.path.join(BASE_DIR, 'static'), filename)
@core_bp.route('/purecss/<path:path>')
def send_pure(path): return send_from_directory(os.path.join(BASE_DIR, 'purecss'), path)

# === è¿½æ›´ API ===

import threading # ç¡®ä¿å¯¼å…¥
@core_bp.route('/api/updates/subscribe', methods=['POST'])
@login_required
def api_subscribe():
    username = session.get('user', {}).get('username')
    data = request.json
    key = data.get('key')
    enable = data.get('enable')
    toc_url = data.get('toc_url')
    
    current_id = data.get('current_id', 0)

    if enable:
        # 1. [ä¿®å¤] æå‰åœ¨ä¸»çº¿ç¨‹é¢„å–æ•°æ®ï¼Œé˜²æ­¢å­çº¿ç¨‹ Context ä¸¢å¤±
        user_db_val = None
        try:
            user_db_val = managers.db.get_val(key)
        except: pass

        managers.update_sub_manager.subscribe(username, key, toc_url, current_id)
        
        def _instant_check(pre_fetched_val):
            print(f"[Instant Check] âš¡ ç”¨æˆ·æ‰‹åŠ¨è®¢é˜… {key}ï¼Œæ­£åœ¨ç«‹å³æ£€æŸ¥æ›´æ–°...")
            try:
                # 0. [æ ¸å¿ƒæ–°å¢] å¼ºåŠ›æ¸…é™¤ç›®å½•é¡µç¼“å­˜ (æ— è®ºçˆ¬è™«æ€ä¹ˆæƒ³ï¼Œç‰©ç†åˆ é™¤ç¼“å­˜æ–‡ä»¶)
                try:
                    from managers import cache
                    cache_file = cache._get_filename(toc_url)
                    if os.path.exists(cache_file):
                        # æ£€æŸ¥ä¸€ä¸‹æ–‡ä»¶æœ€åä¿®æ”¹æ—¶é—´ï¼Œå¦‚æœæ˜¯1åˆ†é’Ÿå†…ç”Ÿæˆçš„ï¼Œå¯èƒ½æ²¡å¿…è¦åˆ 
                        # ä½†ä¸ºäº†ä¿è¯â€œç«‹å³æ£€æŸ¥â€çš„æ‰¿è¯ºï¼Œè¿˜æ˜¯åˆ äº†å¥½
                        os.remove(cache_file)
                        print(f"[Instant Check] å·²å¼ºåˆ¶æ¸…ç†TOCç¼“å­˜: {toc_url}")
                except Exception as e:
                    print(f"[Instant Check] æ¸…ç†ç¼“å­˜å¤±è´¥(å¯èƒ½æ–‡ä»¶è¢«å ç”¨): {e}")

                # =========================================================
                # æ ¸å¿ƒé€»è¾‘ä¿®æ­£ï¼šå¯¹æ¯”åŸºå‡†åº”è¯¥æ˜¯ [æœ¬åœ°ç¼“å­˜TOCçš„æœ€åä¸€ç« ]
                # è€Œä¸æ˜¯ [ç”¨æˆ·å½“å‰çš„é˜…è¯»è¿›åº¦]
                # =========================================================

                # --- 1. è·å–æœ¬åœ°å·²çŸ¥è¿›åº¦ (Local Knowledge) ---
                local_seq = -1
                local_title = "æœªçŸ¥"
                
                # ç­–ç•¥A (æœ€å‡†ç¡®)ï¼šè¯»å–æœ¬åœ°ç¼“å­˜çš„ç›®å½•æ–‡ä»¶çš„æœ€åä¸€ç« 
                cached_toc = managers.cache.get(toc_url)
                if cached_toc and cached_toc.get('chapters'):
                    local_last_chap = cached_toc['chapters'][-1]
                    local_title = local_last_chap.get('title', '')
                    local_seq = parse_chapter_id(local_title)
                    # å¦‚æœæ ‡é¢˜è§£æå¤±è´¥ï¼Œå°è¯•ç”¨åŸå§‹ID (é’ˆå¯¹ç•ªèŒ„ç­‰ç‰¹æ®Šæº)
                    if local_seq == -1 and 'id' in local_last_chap:
                        # æ³¨æ„ï¼šè¿™é‡Œå¦‚æœæ˜¯ç•ªèŒ„çš„é•¿IDï¼Œåé¢ä¼šåœ¨æ¯”è¾ƒç¯èŠ‚å¤„ç†
                        pass 
                    
                    print(f"[Check] æœ¬åœ°ç¼“å­˜TOCå‘½ä¸­: æœ€åä¸€ç«  {local_title} -> {local_seq}")

                # ç­–ç•¥B (å…œåº•)ï¼šå¦‚æœå®Œå…¨æ²¡æœ‰TOCç¼“å­˜ï¼Œæ‰é€€åŒ–ä¸ºä½¿ç”¨é˜…è¯»è¿›åº¦
                # (åœºæ™¯ï¼šåˆšåŠ ä¹¦æ¶è¿˜æ²¡ç‚¹å¼€è¿‡ç›®å½•ï¼Œæˆ–è€…ç¼“å­˜è¢«æ¸…ç©º)
                if local_seq == -1:
                    print(f"[Check] æœ¬åœ°æ— TOCç¼“å­˜ï¼Œå°è¯•ä½¿ç”¨é˜…è¯»è¿›åº¦ä½œä¸ºåŸºå‡†...")
                    current_reading_url = None
                    if isinstance(pre_fetched_val, dict):
                        current_reading_url = pre_fetched_val.get('url')
                    elif isinstance(pre_fetched_val, str):
                        current_reading_url = pre_fetched_val
                    
                    if current_reading_url:
                        cached_chap = managers.cache.get(current_reading_url)
                        if cached_chap and cached_chap.get('title'):
                            local_title = cached_chap['title']
                            local_seq = parse_chapter_id(local_title)
                            print(f"[Check] é˜…è¯»è¿›åº¦å…œåº•: {local_title} -> {local_seq}")
                
                # --- 2. è·å–è¿œç¨‹è¿›åº¦ (Remote) ---
                latest_data = crawler.get_latest_chapter(toc_url, no_cache=True)
                remote_seq = -1
                remote_title = "æœªçŸ¥"
                remote_id = -1
                
                if latest_data:
                    remote_title = latest_data.get('title', '')
                    remote_id = latest_data.get('id')
                    remote_seq = parse_chapter_id(remote_title)
                    if remote_seq == -1 and isinstance(latest_data.get('id'), int):
                         remote_seq = latest_data['id']
                    
                    # [æ ¸å¿ƒä¿®å¤] å†³å®šå…¥åº“çš„ ID
                    # å¦‚æœèƒ½è§£æå‡ºåºå·(å¦‚ 1704)ï¼Œå¿…é¡»å­˜åºå·ï¼Œå¦åˆ™ä¼šå¯¼è‡´å‰ç«¯è®¡ç®—å‡ºå‡ äº¿çš„å·®å€¼
                    # åªæœ‰è§£æå¤±è´¥æ—¶ï¼Œæ‰å­˜åŸå§‹ ID
                    id_to_save = remote_seq if remote_seq > 0 else remote_id;
                    
                    print(f"[Check] è¿œç¨‹è·å–æˆåŠŸ: {remote_title} -> åºå· {remote_seq} (åŸå§‹ID: {remote_id})")
                else:
                    return

                # --- 3. æ ¸å¿ƒæ¯”å¯¹ ---
                print(f"[Check] æœ€ç»ˆæ¯”å¯¹: Local({local_seq}) vs Remote({remote_seq})")
                
                has_update = False
                
                # A. åºå·æ¯”å¯¹ (æœ€ä¼˜å…ˆ)
                if local_seq > 0 and remote_seq > 0:
                    if remote_seq > local_seq:
                        has_update = True
                
                # B. æ ‡é¢˜æ¯”å¯¹ (å…œåº•ï¼Œé˜²æ­¢åºå·è§£æå¤±è´¥)
                # åªæœ‰å½“æœ¬åœ°å·²ç»æœ‰ä¸€å®šçš„æ•°æ®(local_seq != -1)æ‰å¯¹æ¯”ï¼Œå¦åˆ™åˆšåŠ ä¹¦æ¶æ²¡ç¼“å­˜å…¨æŠ¥æ›´æ–°ä¹Ÿä¸å¤ªå¯¹
                elif local_title != "æœªçŸ¥" and local_title != remote_title:
                     has_update = True
                     # å¦‚æœæ˜¯ç•ªèŒ„æºé•¿IDåœºæ™¯ï¼Œå¯èƒ½èµ°åˆ°è¿™é‡Œ
                     print(f"[Check] æ ‡é¢˜/ID å˜åŠ¨è§¦å‘æ›´æ–°: {local_title} != {remote_title}")

                if has_update:
                     # [ä¿®å¤] ä¼ å…¥ id_to_save è€Œä¸æ˜¯ remote_id
                     managers.update_sub_manager.update_status(key, id_to_save, True)
                     print(f"âœ… å‘ç°æ›´æ–° (å­˜å…¥ID: {id_to_save})")
                else:
                     # å…³é”®ï¼šå¦‚æœæ²¡æœ‰æ›´æ–°ï¼Œä¹Ÿè¦æ›´æ–°ä¸€ä¸‹ update_sub_manager é‡Œçš„ last_check_time å’Œ latest_id
                     # è¿™æ ·å‰ç«¯å¯ä»¥æ˜¾ç¤ºâ€œåˆšåˆšæ£€æŸ¥è¿‡â€
                     # [ä¿®å¤] ä¼ å…¥ id_to_save è€Œä¸æ˜¯ remote_id
                     managers.update_sub_manager.update_status(key, id_to_save, False)
                     print(f"ğŸ’¤ æ— æ›´æ–° (å·²åŒæ­¥çŠ¶æ€, å­˜å…¥ID: {id_to_save})")

            except Exception as e:
                import traceback
                traceback.print_exc()
                print(f"[Instant Check] å¤±è´¥: {e}")

        threading.Thread(target=_instant_check, args=(user_db_val,), daemon=True).start()

        return jsonify({"status": "success", "msg": "å·²å¼€å¯è¿½æ›´ï¼Œæ­£åœ¨åå°ç«‹å³æ£€æŸ¥..."})
    else:
        managers.update_sub_manager.unsubscribe(key)
        return jsonify({"status": "success", "msg": "å·²å–æ¶ˆè¿½æ›´"})

@core_bp.route('/api/updates/status', methods=['POST'])
@login_required
def api_updates_status():
    """è¿”å›ç»™å®š key çš„è¿½æ›´çŠ¶æ€ï¼ŒåŒ…å«æ˜¯å¦æœ‰çº¢ç‚¹"""
    key = request.json.get('key')
    # [ä¿®æ”¹] è°ƒç”¨æ–°æ–¹æ³•è·å–è¯¦ç»†ä¿¡æ¯
    status = managers.update_sub_manager.get_book_status(key)
    return jsonify({
        "status": "success", 
        "subscribed": status['subscribed'],
        "has_update": status['has_update'] # å‘Šè¯‰å‰ç«¯æœ‰æ²¡æœ‰æ–°ç« èŠ‚
    })

@core_bp.route('/api/updates/all_red_dots')
@login_required
def api_all_red_dots():
    """é¦–é¡µç”¨ï¼šä¸€æ¬¡æ€§è¿”å›æ‰€æœ‰æœ‰çº¢ç‚¹çš„ book_key"""
    username = session.get('user', {}).get('username')
    keys = managers.update_sub_manager.get_all_updates(username)
    return jsonify({"status": "success", "data": keys})