from flask import Blueprint, render_template_string, request, jsonify, send_file, render_template, redirect, url_for, send_from_directory, session
import requests
import os
from shared import login_required, is_safe_url, BASE_DIR, DL_DIR
import managers
from spider_core import crawler_instance as crawler, searcher, epub_handler, parse_chapter_id
import re
core_bp = Blueprint('core', __name__)
DEFAULT_SERVER = 'https://auth.ztrztr.top'
DEFAULT_CALLBACK = 'https://book.ztrztr.top/callback'
# æ³¨æ„ï¼šCLIENT_ID å’Œ SECRET é€šå¸¸ä¸å»ºè®®ç¡¬ç¼–ç é»˜è®¤å€¼ï¼Œ
# ä½†ä¸ºäº†é…åˆä½ çš„é€»è¾‘ï¼Œå¦‚æœ .env æ²¡å¡«ï¼Œè¿™é‡Œå¯ä»¥ç•™ç©ºæˆ–è€…å†™æ­»ä½ çš„å¤‡ç”¨ Key
DEFAULT_CLIENT_ID = None 
DEFAULT_CLIENT_SECRET = None
CLIENT_ID = os.environ.get('CLIENT_ID') or DEFAULT_CLIENT_ID
CLIENT_SECRET = os.environ.get('CLIENT_SECRET') or DEFAULT_CLIENT_SECRET
AUTH_SERVER = os.environ.get('SERVER', 'https://auth.ztrztr.top')
REDIRECT_URI = os.environ.get('CALLBACK', 'https://book.ztrztr.top/callback')
def calculate_real_chapter_id(book_key, chapter_url, chapter_title):
    """
    åªé€šè¿‡æ ‡é¢˜è¯†åˆ«çœŸå®åºå·ã€‚
    å¦‚æœè¯†åˆ«ä¸åˆ°ï¼Œè¿”å› -1ï¼Œä¸å†å°è¯•ä» URL ççŒœã€‚
    """
    if chapter_url.startswith('epub:'):
        return -1
    # ç­–ç•¥ A: æ ‡é¢˜è§£æ (ä½¿ç”¨æˆ‘ä»¬åˆšåˆšä¿®å¥½çš„å¢å¼ºç‰ˆå‡½æ•°)
    title_id = parse_chapter_id(chapter_title)
    if title_id > 0:
        return title_id
    
    # ç­–ç•¥ B: ä¸¥æ ¼æ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬ä¸å†ä» URL æ­£åˆ™æå– IDï¼Œ
    # å› ä¸º URL ID å¾€å¾€æ˜¯ç½‘ç«™æ•°æ®åº“çš„ ID (å¦‚ 5882.html)ï¼Œè€Œä¸æ˜¯ç¬¬å‡ ç« ã€‚
    # å¦‚æœä½ ç¡®å®šæŸäº›ç½‘ç«™ URL å°±æ˜¯ç« èŠ‚å·ï¼Œå¯ä»¥ä¿ç•™ï¼Œä½†ç›®å‰ä¸ºäº†é˜²è¯¯æŠ¥ï¼Œå»ºè®®å…³é—­ã€‚
    
    return -1
@core_bp.route('/login')
def login(): return redirect(f"{AUTH_SERVER}/oauth/authorize?client_id={CLIENT_ID}&redirect_uri={REDIRECT_URI}")

@core_bp.route('/callback')
def callback():
    code = request.args.get('code')
    try:
        resp = requests.post(f"{AUTH_SERVER}/oauth/token", json={'grant_type': 'authorization_code', 'client_id': CLIENT_ID, 'client_secret': CLIENT_SECRET, 'code': code}).json()
        if 'access_token' in resp:
            u = requests.get(f"{AUTH_SERVER}/api/user", headers={'Authorization': f"Bearer {resp['access_token']}"}).json()
            session.permanent = True
            session['user'] = u
            return redirect(url_for('core.index'))
    except: pass
    return "Login Failed", 400

@core_bp.route('/logout')
def logout(): session.clear(); return redirect('/')
from spider_core import parse_chapter_id
# [æ–°å¢] è§£æé¡µç çš„è¾…åŠ©å‡½æ•°
def get_page_index(url):
    """ä» URL è§£æé¡µç  (ä¾‹å¦‚ 123_2.html -> 2, 123.html -> 1)"""
    try:
        # åŒ¹é… _2.html è¿™ç§æ ¼å¼
        match = re.search(r'_(\d+)\.', url)
        if match:
            return int(match.group(1))
    except: pass
    return 1 # é»˜è®¤æ˜¯ç¬¬ 1 é¡µ
# routes/core_bp.py

from flask import make_response # è®°å¾—å¼•å…¥è¿™ä¸ª

@core_bp.route('/api/me')
def api_me():
    # 1. è·å– Session ä¸­çš„åŸºç¡€ä¿¡æ¯
    user = session.get('user', {"username": None})
    
    # 2. ã€æ ¸å¿ƒã€‘å®æ—¶æŸ¥è¯¢å¹¶æ³¨å…¥è§’è‰²æƒé™
    # å³ä½¿ Session é‡Œæ²¡å­˜ roleï¼Œè¿™é‡Œä¹Ÿè¦æŸ¥å‡ºæ¥å¡è¿›å»
    if user.get('username'):
        # è¿™é‡Œçš„ managers.role_manager éœ€è¦ç¡®ä¿å·²å¯¼å…¥
        user['role'] = managers.role_manager.get_role(user['username'])
    
    # 3. ã€æ ¸å¿ƒã€‘æ„å»ºå“åº”å¹¶ç¦æ­¢ç¼“å­˜
    response = make_response(jsonify(user))
    # å‘Šè¯‰æµè§ˆå™¨å’Œ CDNï¼šä¸è¦ç¼“å­˜è¿™ä¸ªè¯·æ±‚ï¼
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    
    return response

@core_bp.route('/')
@login_required
def index():
    # æ—§ä»£ç : return send_file(os.path.join(BASE_DIR, 'index.html'))
    
    # === [æ–°ä»£ç ] è¯»å–æ–‡ä»¶å¹¶å½“åšæ¨¡æ¿æ¸²æŸ“ ===
    try:
        # index_path = os.path.join(BASE_DIR, 'index.html')
        # with open(index_path, 'r', encoding='utf-8') as f:
        #     html_content = f.read()
        
        # è¿™é‡Œçš„ render_template_string ä¼šè‡ªåŠ¨æ¥æ”¶ context_processor æ³¨å…¥çš„ app_version
        return render_template("index.html", 
        api_url="")
    except Exception as e:
        return f"Error loading index: {str(e)}", 500

@core_bp.route('/read')
@login_required
def read_mode():
    u, k = request.args.get('url'), request.args.get('key', '')
    force = request.args.get('force')
    
    # 1. å®‰å…¨æ£€æŸ¥ (æ”¾è¡Œ epub åè®®)
    if not u.startswith('epub:') and not is_safe_url(u): 
        return "Illegal URL", 403
    
    data = None
    
    # 2. è·å–æ•°æ® (EPUB æˆ– ç½‘é¡µ)
    try:
        if u.startswith('epub:'):
            # EPUB å¤„ç†é€»è¾‘
            parts = u.split(':')
            filename = parts[1]
            
            # å¦‚æœæ˜¯ç›®å½•è¯·æ±‚ï¼Œè·³è½¬åˆ° TOC
            if len(parts) >= 3 and parts[2] == 'toc':
                return redirect(url_for('core.toc_page', url=u, key=k))
            
            # è§£ææ ‡è¯†ç¬¦å’Œé¡µç 
            if len(parts) >= 4:
                identifier = parts[2]
                page_index = int(parts[3])
            else:
                identifier = parts[2]
                page_index = 0
            
            data = epub_handler.get_chapter_content(filename, identifier, page_index)
        else:
            # ç½‘é¡µçˆ¬è™«é€»è¾‘
            data = managers.offline_manager.get_chapter(k, u) if k and not force else None
            if not data and not force: data = managers.cache.get(u)
            if not data:
                data = crawler.run(u)
                if data: managers.cache.set(u, data)
    except Exception as e:
        return f"è§£æé”™è¯¯: {e}", 500

    if not data:
        return "æ— æ³•è·å–å†…å®¹ï¼Œè¯·æ£€æŸ¥é“¾æ¥æˆ–ç¨åé‡è¯•", 404

    # 3. è®°å½•å†å² & è®¡ç®—ç« èŠ‚ ID
    if k and data.get('title'):
        managers.history_manager.add_record(k, data['title'], u, data.get('book_name'))

    current_chapter_id = -1
    if data.get('title'):
        current_chapter_id = parse_chapter_id(data['title'])
    
    # å¦‚æœæ ‡é¢˜è§£æå¤±è´¥ï¼Œå°è¯•ä» URL æå– (ä»…é’ˆå¯¹ç½‘é¡µ)
    if current_chapter_id <= 0 and not u.startswith('epub:'):
        match = re.search(r'/(\d+)(?:_\d+)?(?:\.html)?$', u.split('?')[0])
        if match: current_chapter_id = int(match.group(1))

    # 4. === [æ ¸å¿ƒä¿®æ”¹] è®¾å¤‡åˆ†æµé€»è¾‘ ===
    ua = request.headers.get('User-Agent', '').lower()
    is_mobile = any(x in ua for x in ['iphone', 'android', 'phone', 'mobile'])
    
    # ç»Ÿä¸€çš„æ¨¡æ¿ä¸Šä¸‹æ–‡å˜é‡
    context = {
        'article': data,
        'current_url': u,
        'db_key': k,
        'chapter_id': current_chapter_id
    }

    if is_mobile:
        # æ‰‹æœºç«¯ -> æ¸²æŸ“ reader_m.html (ä¸€å®šè¦ç¡®ä¿è¿™ä¸ªæ–‡ä»¶åœ¨ templates é‡Œ)
        return render_template('reader_m.html', **context)
    else:
        # ç”µè„‘ç«¯ -> æ¸²æŸ“ reader_pc.html
        return render_template('reader_pc.html', **context)
@core_bp.route('/api/history/list')
@login_required
def api_history_list():
    return jsonify({"status": "success", "data": managers.history_manager.get_history()})

@core_bp.route('/api/history/clear', methods=['POST'])
@login_required
def api_history_clear():
    managers.history_manager.clear()
    return jsonify({"status": "success"})
@core_bp.route('/toc')
@login_required
def toc_page():
    u, k = request.args.get('url'), request.args.get('key', '')
    # æ¥æ”¶ force å‚æ•°ï¼Œå¦‚æœæ˜¯ 'true' åˆ™è·³è¿‡ç¼“å­˜
    force = request.args.get('force') == 'true'
    is_api = request.args.get('api')
    if u.startswith('epub:'):
        # åè®®æ ¼å¼ï¼šepub:æ–‡ä»¶å:ç´¢å¼• (ä¾‹å¦‚ epub:test.epub:toc)
        parts = u.split(':')
        filename = parts[1]
        data = epub_handler.get_toc(filename)
        
        if not data:
            return "EPUB ç›®å½•è§£æå¤±è´¥", 404
            
        if is_api:
            return jsonify(data)
        return render_template('toc.html', toc=data, toc_url=u, db_key=k)
    data = None if force else managers.cache.get(u)
    
    if not data:
        data = crawler.get_toc(u)
        if data:
            managers.cache.set(u, data)
    
    if is_api:
        return jsonify(data if data else {"status": "error", "message": "æ— æ³•è·å–ç›®å½•"})

    return render_template('toc.html', toc=data, toc_url=u, db_key=k)

@core_bp.route('/list', methods=['POST'])
@login_required
def list_all(): return jsonify(managers.db.list_all())

@core_bp.route('/find', methods=['POST'])
@login_required
def find(): return jsonify(managers.db.find(request.json.get('key', '')))

@core_bp.route('/insert', methods=['POST'])
@login_required
def insert():
    key = request.json.get('key')
    raw_value = request.json.get('value') # åŸå§‹è¾“å…¥
    is_manual = request.json.get('manual', False)
    
    # [æ ¸å¿ƒä¿®æ”¹] æ™ºèƒ½çº é”™
    # åªæœ‰åœ¨æ‰‹åŠ¨è¾“å…¥æ—¶æ‰å°è¯•çº é”™ï¼Œè‡ªåŠ¨åŒæ­¥æ—¶ä¸çº é”™(èŠ‚çœæ€§èƒ½)
    final_value = raw_value
    if is_manual:
        # è°ƒç”¨çˆ¬è™«çš„æ™ºèƒ½è§£æ
        final_value = crawler.resolve_start_url(raw_value)
    
    # ä¿å­˜çº é”™åçš„å€¼
    res = managers.db.insert(key, final_value)
    
    if is_manual and res.get('status') == 'success':
        managers.db.add_version(key, final_value)
        
    return jsonify(res)

import time
@core_bp.route('/update', methods=['POST'])
@login_required
def update():
    key = request.json.get('key')
    value = request.json.get('value')
    title = request.json.get('title', '') 
    is_manual = request.json.get('manual', False)

    # 1. ä¿å­˜ URL (è¿™æ˜¯åŸºç¡€ KV è®°å½•)
    final_value = value
    if is_manual and hasattr(crawler, 'resolve_start_url'):
        final_value = crawler.resolve_start_url(value)
    
    res = managers.db.update(key, final_value)

    # 2. ã€æ ¸å¿ƒä¿®æ”¹ç‚¹ã€‘è®¡ç®—å¹¶ä¿å­˜åºå·
    real_id = calculate_real_chapter_id(key, final_value, title)
    
    # åªæœ‰å½“ real_id æ˜¯æœ‰æ•ˆæ­£æ•´æ•°æ—¶æ‰æ›´æ–° meta
    # å¦‚æœè¿”å› -1 (æœªè¯†åˆ«)ï¼Œè¿™é‡Œç›´æ¥è·³è¿‡ï¼Œæ•°æ®åº“é‡Œæ—§çš„ meta ä¼šä¿ç•™
    if real_id > 0:
        try:
            import json
            # è·å–æ—§ meta
            old_meta_str = managers.db.get_val(f"{key}:meta")
            meta = json.loads(old_meta_str) if old_meta_str else {}
            
            # æ›´æ–°åºå·å’Œæ—¶é—´æˆ³
            meta['chapter_id'] = real_id
            meta['updated_at'] = int(time.time())
            
            managers.db.update(f"{key}:meta", json.dumps(meta))
            # print(f"[Sync] è¯†åˆ«æˆåŠŸï¼š{title} -> ID {real_id}")
        except Exception as e:
            print(f"[Sync] Meta save error: {e}")
    else:
        # å¦‚æœæ²¡è¯†åˆ«åˆ°ï¼Œæ‰“å°ä¸€ä¸ªæ—¥å¿—æ–¹ä¾¿è°ƒè¯•ï¼Œä½†ä¸å†™åº“
        print(f"[Sync] âš ï¸ ç« èŠ‚è¯†åˆ«å¤±è´¥ï¼Œè·³è¿‡ Meta è®°å½•: {title}")

    # 3. å†å²ç‰ˆæœ¬ (ä»…æ‰‹åŠ¨)
    if is_manual and res.get('status') == 'success':
        managers.db.add_version(key, final_value)
    
    return jsonify(res)
# routes/core_bp.py

@core_bp.route('/api/rename_key', methods=['POST'])
@login_required
def api_rename_key():
    old_key = request.json.get('old_key')
    new_key = request.json.get('new_key')
    
    if not old_key or not new_key:
        return jsonify({"status": "error", "message": "å‚æ•°ä¸è¶³"})
    
    # è°ƒç”¨åˆšæ‰åœ¨ managers é‡Œå†™çš„é€»è¾‘
    res = managers.db.rename_key(old_key, new_key)
    return jsonify(res)
@core_bp.route('/api/switch_source', methods=['POST'])
@login_required
def api_switch_source():
    current_url = request.json.get('url')
    book_key = request.json.get('key')
    
    if not current_url or not book_key:
        return jsonify({"status": "error", "msg": "Missing params"})

    try:
        # 1. è·å–å½“å‰ä¹¦å (ä»ä¹¦å•æˆ–ç¼“å­˜æ‹¿ï¼Œæˆ–è€…é‡æ–°çˆ¬å½“å‰é¡µ)
        # ä¸ºäº†å‡†ç¡®ï¼Œæˆ‘ä»¬å…ˆå°è¯•ä»ç¼“å­˜æ‹¿å½“å‰é¡µä¿¡æ¯
        book_name = ""
        current_id = -1
        
        cached_page = managers.cache.get(current_url)
        if cached_page:
            # å°è¯•ä»é¡µé¢æ ‡é¢˜æå–ä¹¦å (é€šå¸¸æ ¼å¼: ç¬¬xxç«  æ ‡é¢˜ - ä¹¦å - ç½‘ç«™å)
            # è¿™æ­¥æ¯”è¾ƒéš¾ï¼Œå¦‚æœç¼“å­˜é‡Œæ²¡å­˜ä¹¦åï¼Œæˆ‘ä»¬åªèƒ½ç”¨ SearchHelper çš„ key åæ¨æˆ–è€…è®©å‰ç«¯ä¼ 
            # ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ç”¨ key (æ‹¼éŸ³) å»ä¹¦å•é‡ŒåæŸ¥ä¹¦åï¼Œæˆ–è€…è®©ç”¨æˆ·å‰ç«¯ä¼ ä¹¦å
            pass
            
        # æ›´å¥½çš„æ–¹æ¡ˆï¼šå‰ç«¯ä¼  book_title è¿‡æ¥ã€‚
        # å¦‚æœå‰ç«¯æ²¡ä¼ ï¼Œæˆ‘ä»¬å»ä¹¦å•ç®¡ç†å™¨é‡ŒæŸ¥è¿™ä¸ª key å¯¹åº”çš„ä¹¦å
        book_name = request.json.get('title')
        if not book_name:
             # å°è¯•ä»ä¹¦å•åæŸ¥
             all_lists = managers.booklist_manager.load()
             for lid, ldata in all_lists.items():
                 for book in ldata.get('books', []):
                     if book['key'] == book_key:
                         book_name = book['title']
                         break
                 if book_name: break
        
        if not book_name:
            return jsonify({"status": "error", "msg": "æ— æ³•è·å–ä¹¦åï¼Œè¯·å…ˆå°†ä¹¦åŠ å…¥ä¹¦å•"})

        # 2. è·å–å½“å‰ç« èŠ‚ ID
        if cached_page and cached_page.get('title'):
             current_id = parse_chapter_id(cached_page['title'])
        
        if current_id <= 0:
             # å°è¯•æ­£åˆ™
             import re
             match = re.search(r'/(\d+)(?:_\d+)?(?:\.html)?$', current_url)
             if match: current_id = int(match.group(1))

        if current_id <= 0:
            return jsonify({"status": "error", "msg": "æ— æ³•è¯†åˆ«å½“å‰ç« èŠ‚ID"})

        # 3. æ‰§è¡Œæ¢æº
        result = crawler.search_and_switch_source(book_name, current_id)
        
        if result:
            # æ‰¾åˆ°æ–°æºäº†ï¼
            new_url = result['new_url']
            
            # 4. æ›´æ–°æ•°æ®åº“ (æ— ç¼è¡”æ¥)
            managers.db.update(book_key, new_url)
            
            # 5. é¡ºä¾¿æ›´æ–°ä¸‹ç¼“å­˜ (é¢„çƒ­)
            # threading.Thread(target=crawler.run, args=(new_url,)).start()
            
            return jsonify({
                "status": "success", 
                "new_url": new_url,
                "msg": f"å·²åˆ‡æ¢è‡³: {result['source_name']}"
            })
        else:
            return jsonify({"status": "failed", "msg": "å…¨ç½‘æœªæ‰¾åˆ°è¯¥ç« èŠ‚çš„å…¶ä»–æº"})

    except Exception as e:
        print(f"Switch Error: {e}")
        return jsonify({"status": "error", "msg": str(e)})
    
# @core_bp.route('/api/source/list', methods=['POST'])
# @login_required
@core_bp.route('/api/source/list', methods=['POST'])
@login_required
def api_source_list():
    current_url = request.json.get('url')
    book_key = request.json.get('key')
    frontend_title = request.json.get('title', '') # ç« èŠ‚æ ‡é¢˜
    
    if not current_url: return jsonify({"status": "error", "msg": "å‚æ•°é”™è¯¯"})

    # === æ ¸å¿ƒé€»è¾‘ï¼šå¤šçº§æ¢æµ‹çœŸå®ä¹¦å ===
    book_name = None
    
    # 1. å°è¯•ä»ä¹¦å•åæŸ¥ (ç”¨æˆ·å®šä¹‰çš„æ ‡é¢˜æœ€ä¼˜å…ˆ)
    all_lists = managers.booklist_manager.load()
    for list_data in all_lists.values():
        for b in list_data.get('books', []):
            if b['key'] == book_key:
                book_name = b['title']
                break
        if book_name: break

    # 2. ã€å…³é”®è¡¥ä¸ã€‘å¦‚æœä¹¦å•æ²¡æ‰¾åˆ°ï¼Œç›´æ¥â€œç°åœºçˆ¬å–â€å½“å‰é˜…è¯»é¡µæå–ä¹¦å
    if not book_name or re.match(r'^[a-zA-Z0-9_]+$', book_name):
        print(f"[Switch] æ— æ³•ä»æœ¬åœ°è·å–ä¹¦åï¼Œæ­£åœ¨ç°åœºçˆ¬å–æºç«™: {current_url}")
        try:
            # ç°åœºçˆ¬å–å½“å‰é¡µé¢å†…å®¹
            # æ³¨æ„ï¼šè¿™é‡Œ run ä¼šè‡ªåŠ¨è¯†åˆ«æ˜¯èµ°æ’ä»¶è¿˜æ˜¯èµ°é€šç”¨é€»è¾‘
            temp_data = crawler.run(current_url)
            if temp_data and temp_data.get('book_name'):
                book_name = temp_data['book_name']
                print(f"[Switch] ğŸ¯ ç°åœºæŠ“å–ä¹¦åæˆåŠŸ: {book_name}")
        except Exception as e:
            print(f"[Switch] ç°åœºæŠ“å–ä¹¦åå¤±è´¥: {e}")

    # 3. æœ€ç»ˆæ ¡éªŒ
    # å¦‚æœè¿˜æ˜¯æ‹¿ä¸åˆ°ä¸­æ–‡ï¼ˆå…¨æ˜¯å­—æ¯æ•°å­—ï¼‰ï¼Œè¯´æ˜çœŸçš„æ²¡æ³•æœ
    if not book_name or re.match(r'^[a-zA-Z0-9_]+$', str(book_name)):
        return jsonify({
            "status": "error", 
            "msg": f"æ— æ³•è¯†åˆ«ä¹¦å(å½“å‰:{book_name})ã€‚å»ºè®®æ‰‹åŠ¨å°†æœ¬ä¹¦åŠ å…¥ä¹¦å•å¹¶å¡«å†™ä¸­æ–‡ä¹¦åã€‚"
        })

    # === è·å–å½“å‰ç« èŠ‚ ID ===
    current_id = parse_chapter_id(frontend_title)
    if current_id <= 0:
         match = re.search(r'/(\d+)(?:_\d+)?(?:\.html)?$', current_url)
         if match: current_id = int(match.group(1))
    
    if current_id <= 0:
        return jsonify({"status": "error", "msg": "æ— æ³•è¯†åˆ«å½“å‰ç« èŠ‚ID"})

    # === æœç´¢å¹¶æ¯”å¯¹ ===
    print(f"[Switch] å‡†å¤‡æœç´¢æ–°æºï¼Œå…³é”®è¯: {book_name}, ç›®æ ‡ç« èŠ‚: {current_id}")
    sources = crawler.search_alternative_sources(book_name, current_id)
    
    if not sources:
        return jsonify({"status": "failed", "msg": "å…¨ç½‘æœªæ‰¾åˆ°åŒ…å«è¯¥ç« èŠ‚çš„å…¶ä»–æº"})
        
    return jsonify({"status": "success", "data": sources})
@core_bp.route('/api/history/versions', methods=['POST'])
@login_required
def api_history_versions():
    key = request.json.get('key')
    if not key: return jsonify({"status": "error"})
    
    versions = managers.db.get_versions(key)
    return jsonify({"status": "success", "data": versions})
@core_bp.route('/remove', methods=['POST'])
@login_required
def remove(): return jsonify(managers.db.remove(request.json.get('key')))

@core_bp.route('/rollback', methods=['POST'])
@login_required
def rollback(): return jsonify(managers.db.rollback())

@core_bp.route('/api/get_value', methods=['POST'])
@login_required
def get_val():
    key = request.json.get('key')
    v = managers.db.get_val(key)
    
    if v:
        # ç›´æ¥è¯»å– metaï¼Œä¸å†è¿›è¡Œä»»ä½•çˆ¬è™«æˆ–è§£æ
        meta_str = managers.db.get_val(f"{key}:meta")
        meta = {}
        if meta_str:
            try: 
                import json
                meta = json.loads(meta_str) 
            except: pass
        
        return jsonify({
            "status": "success", 
            "value": v,
            "meta": meta # è¿™é‡Œé¢åŒ…å«å‡†ç¡®çš„ chapter_id
        })
        
    return jsonify({"status": "error"})

@core_bp.route('/api/last_read', methods=['GET', 'POST'])
@login_required
def handle_last_read():
    if request.method == 'GET': return jsonify({"status": "success", "key": managers.db.get_val('@last_read')})
    return jsonify(managers.db.insert('@last_read', request.json.get('key')))

@core_bp.route('/api/tags/list')
@login_required
def api_tags_list(): return jsonify({"status": "success", "data": managers.tag_manager.get_all()})

@core_bp.route('/api/tags/update', methods=['POST'])
@login_required
def api_tags_update(): return jsonify({"status": "success", "tags": managers.tag_manager.update_tags(request.json.get('key'), request.json.get('tags', []))})

@core_bp.route('/api/analyze_stats')
@login_required
def api_analyze_stats(): return jsonify({"status": "success", "summary": managers.stats_manager.get_summary(), "keywords": []})

@core_bp.route('/api/stats/heartbeat', methods=['POST'])
@login_required
def api_heartbeat():
    d = request.json
    managers.stats_manager.update(60 if d.get('is_heartbeat') else 0, d.get('words', 0), 1 if d.get('words', 0)>0 else 0, d.get('book_key'))
    return jsonify({"status": "success"})

@core_bp.route('/api/booklists/all')
@login_required
def api_booklists_all(): return jsonify({"status": "success", "data": managers.booklist_manager.load()})

@core_bp.route('/api/booklists/create', methods=['POST'])
@login_required
def api_booklists_create(): return jsonify({"status": "success", "id": managers.booklist_manager.add_list(request.json.get('name'))})

@core_bp.route('/api/booklists/add_book', methods=['POST'])
@login_required
def api_booklists_add(): 
    managers.booklist_manager.add_to_list(request.json['list_id'], request.json['book_data'])
    return jsonify({"status": "success"})

@core_bp.route('/api/prefetch', methods=['POST'])
@login_required
def api_prefetch():
    u = request.json.get('url')
    if managers.cache.get(u): return jsonify({"status": "skipped"})
    d = crawler.run(u)
    if d:
        managers.cache.set(u, d)
        return jsonify({"status": "success"})
    return jsonify({"status": "failed"})

@core_bp.route('/api/resolve_head', methods=['POST'])
@login_required
def api_resolve_head():
    try: return jsonify({"status": "success", "url": crawler.get_first_chapter(request.json.get('url'))})
    except: return jsonify({"status": "error"})

@core_bp.route('/api/search_novel', methods=['POST'])
@login_required
def api_search(): return jsonify({"status": "success", "data": searcher.search_bing(request.json.get('keyword'))})

@core_bp.route('/api/upload_epub', methods=['POST'])
@login_required
def api_upload_epub():
    if 'file' not in request.files: return jsonify({"status": "error"})
    f = request.files['file']
    fn = epub_handler.save_file(f)
    k = searcher.get_pinyin_key(os.path.splitext(fn)[0])
    v = f"epub:{fn}:toc"
    managers.db.insert(k, v)
    return jsonify({"status": "success", "key": k, "value": v})
# ... å¼•å…¥ update_manager ...
from managers import db, update_manager, booklist_manager

# 1. æ‰‹åŠ¨æ£€æŸ¥å•æœ¬æ›´æ–°
@core_bp.route('/api/check_update', methods=['POST'])
@login_required
def api_check_update():
    # å‰ç«¯ä¼ æ¥çš„å½“å‰é˜…è¯» URL
    current_url = request.json.get('url') 
    book_key = request.json.get('key')
    
    if not current_url: return jsonify({"status": "error", "msg": "No URL"})

    try:
        # 1. æ™ºèƒ½æ‰¾ç›®å½• (ä¼˜å…ˆç¼“å­˜)
        toc_url = None
        cached_page = managers.cache.get(current_url)
        if cached_page and cached_page.get('toc_url'): 
            toc_url = cached_page['toc_url']
        else:
            page_data = crawler.run(current_url)
            if page_data: 
                toc_url = page_data.get('toc_url')
                managers.cache.set(current_url, page_data)

        if not toc_url: 
            # å…œåº•çŒœæµ‹
            toc_url = current_url.rsplit('/', 1)[0] + '/'

        # 2. çˆ¬å–æœ€æ–°ç« èŠ‚ (è¿™æ˜¯æ‰‹åŠ¨æ£€æŸ¥ï¼Œå¿…é¡»å®æ—¶çˆ¬)
        latest_chap = crawler.get_latest_chapter(toc_url)
        
        if latest_chap:
            # 3. ä¿å­˜æœ€æ–°ä¿¡æ¯åˆ°ç¡¬ç›˜ (ç»™è‡ªåŠ¨è½®è¯¢ç”¨)
            save_data = {
                "latest_title": latest_chap['title'],
                "latest_url": latest_chap['url'],
                "latest_id": latest_chap['id'],
                "toc_url": toc_url
            }
            managers.update_manager.set_update(book_key, save_data)
            
            # ===============================================
            # 4. [æ ¸å¿ƒä¿®å¤] ç«‹å³è®¡ç®—å·®å€¼è¿”å›ç»™å‰ç«¯
            # ===============================================
            
            # A. è·å–å½“å‰é˜…è¯»è¿›åº¦çš„ ID
            current_id = parse_chapter_id(current_url)
            # å¦‚æœ URL é‡Œæ²¡ ID æˆ–è€…æ˜¯ _2.htmlï¼Œå°è¯•æ­£åˆ™æå–
            if current_id <= 0:
                match = re.search(r'/(\d+)(?:_\d+)?(?:\.html)?$', current_url)
                if match: current_id = int(match.group(1))

            latest_id = latest_chap['id']
            
            # æ„é€ è¿”å›ç»™å‰ç«¯çš„è¯¦ç»†æ•°æ®
            response_data = {
                "latest_title": latest_chap['title'],
                "latest_url": latest_chap['url'],
                "unread_count": 0,
                "status_text": "å·²æœ€æ–°"
            }

            # B. æ‰§è¡Œå‡æ³•
            if latest_id > 0 and current_id > 0:
                diff = latest_id - current_id
                if diff > 0:
                    response_data["unread_count"] = diff
                    response_data["status_text"] = f"è½å {diff} ç« "
                else:
                    response_data["status_text"] = "å·²è¿½å¹³"
            elif current_url != latest_chap['url']:
                # ID è§£æå¤±è´¥ï¼Œå›é€€åˆ° URL å¯¹æ¯”
                response_data["unread_count"] = 1
                response_data["status_text"] = "æœ‰æ–°ç« èŠ‚"

            return jsonify({
                "status": "success", 
                "msg": "åˆ·æ–°æˆåŠŸ", 
                "data": response_data  # æŠŠç®—å¥½çš„æ•°æ®ä¼ å›å»
            })
        else:
            return jsonify({"status": "failed", "msg": "ç›®å½•è§£æå¤±è´¥"})

    except Exception as e:
        print(f"Check Update Error: {e}")
        return jsonify({"status": "error", "msg": str(e)})
# 2. è·å–æ‰€æœ‰æ›´æ–°çŠ¶æ€ (ç”¨äºå‰ç«¯æ¸²æŸ“å°çº¢ç‚¹)
from spider_core import searcher, epub_handler, parse_chapter_id 

# =========================================================
# æ ¸å¿ƒæ¥å£ 1ï¼šè·å–æ‰€æœ‰ä¹¦çš„å®æ—¶çŠ¶æ€ (å‰ç«¯åˆ·æ–°/è½®è¯¢è°ƒç”¨)
# =========================================================
# routes/core_bp.py

# routes/core_bp.py

@core_bp.route('/api/updates/status')
@login_required
def api_get_updates_status():
    # 1. å¯»æ‰¾ target_books (åªæ£€æŸ¥ to_read ä¹¦å•é‡Œçš„ä¹¦)
    all_lists = managers.booklist_manager.load()
    target_books = []
    
    # å…³é”®å­—åŒ¹é…ä¹¦å•å
    watch_keywords = ['to_read', 'å¿…è¯»', 'è¿½æ›´', 'reading', 'åœ¨è¯»']
    
    for list_data in all_lists.values():
        list_name = list_data.get('name', '').lower()
        if any(k in list_name for k in watch_keywords):
            target_books.extend(list_data.get('books', []))
            
    # å¦‚æœæ²¡æœ‰åŒ¹é…çš„ä¹¦å•ï¼Œä¸ºäº†å…¼å®¹æ€§ï¼Œå¯ä»¥æ£€æŸ¥ä¸€ä¸‹ status='want' çš„ä¹¦
    if not target_books:
        for list_data in all_lists.values():
            for book in list_data.get('books', []):
                if book.get('status') == 'want':
                    target_books.append(book)

    # å»é‡
    target_keys = list(set([b['key'] for b in target_books]))
    
    # è·å–æ›´æ–°è®°å½• (æ¥è‡ªåå°çˆ¬è™«)
    updates_record = managers.update_manager.load()
    
    response_data = {}
    
    # è·å–ç”¨æˆ·å½“å‰çš„é˜…è¯»è¿›åº¦ (KV Store)
    user_progress = managers.db.list_all().get('data', {})

    print(f"\n[StatusCheck] æ­£åœ¨ä¸º {len(target_keys)} æœ¬è¿½æ›´ä¹¦ç±è®¡ç®—è¿›åº¦...")

    for key in target_keys:
        current_url = user_progress.get(key)
        if not current_url: continue

        # --- A. è·å–å½“å‰é˜…è¯»ç« èŠ‚çš„ ID (æœ€ç²¾å‡†çš„æ–¹æ³•ï¼šçˆ¬å½“å‰é¡µ) ---
        current_id = -1
        
        # 1. å…ˆå°è¯•ä»ç¼“å­˜è¯»é¡µé¢ä¿¡æ¯ (é¿å…é¢‘ç¹çˆ¬å–)
        cached_page = managers.cache.get(current_url)
        if cached_page and cached_page.get('title'):
            # ä½¿ç”¨ç»Ÿä¸€çš„ parse_chapter_id å‡½æ•°
            current_id = parse_chapter_id(cached_page['title'])
        
        # 2. å¦‚æœç¼“å­˜æ²¡æœ‰æˆ–æ²¡è§£æå‡ºIDï¼Œä¸”ä¸æ˜¯é¢‘ç¹è¯·æ±‚ï¼Œæ‰å°è¯•çˆ¬å–
        if current_id <= 0:
            # è¿™é‡Œä¸ºäº†æ€§èƒ½ï¼Œå¦‚æœç”¨æˆ·çŸ­æ—¶é—´å†…é¢‘ç¹åˆ·æ–°ï¼Œæˆ‘ä»¬ä¸åº”è¯¥æ¯æ¬¡éƒ½å»çˆ¬
            # ä½†ä¸ºäº†å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬å‡è®¾ç”¨æˆ·å·²ç»é˜…è¯»äº†æ–°ç« èŠ‚
            try:
                page_data = crawler.run(current_url)
                if page_data and page_data.get('title'):
                    managers.cache.set(current_url, page_data) # é¡ºæ‰‹å­˜ç¼“å­˜
                    current_id = parse_chapter_id(page_data['title'])
            except: pass
        
        # 3. å®åœ¨ä¸è¡Œï¼Œå›é€€åˆ° URL æ­£åˆ™æå–
        if current_id <= 0:
            match = re.search(r'/(\d+)(?:_\d+)?(?:\.html)?$', current_url)
            if match: current_id = int(match.group(1))

        # --- B. è·å–æœ€æ–°ç« èŠ‚ ID (æ¥è‡ª update_manager) ---
        latest_info = updates_record.get(key)
        if not latest_info: continue

        latest_id = int(latest_info.get('latest_id', -1))
        # å¦‚æœ json é‡Œå­˜çš„ latest_id æ— æ•ˆï¼Œå°è¯•ä» latest_title ç°ç®—
        if latest_id <= 0 and latest_info.get('latest_title'):
             latest_id = parse_chapter_id(latest_info['latest_title'])

        # --- C. è®¡ç®—å·®å€¼ ---
        status_payload = {
            "unread_count": 0,
            "status_text": "å·²æœ€æ–°",
            "latest_title": latest_info.get('latest_title', '')
        }

        if latest_id > 0 and current_id > 0:
            diff = latest_id - current_id
            # åªæœ‰æ­£å‘å·®è·æ‰ç®—æ›´æ–° (é˜²æ­¢çœ‹ç•ªå¤–å¯¼è‡´ ID å˜å°)
            if diff > 0:
                status_payload['unread_count'] = diff
                status_payload['status_text'] = f"è½å {diff} ç« "
            else:
                status_payload['status_text'] = "å·²è¿½å¹³"
        
        # å­˜å…¥ç»“æœ
        response_data[key] = status_payload

    return jsonify(response_data)
@core_bp.route('/api/download', methods=['POST'])
@login_required
def start_dl():
    d = request.json
    toc = managers.cache.get(d['toc_url']) or crawler.get_toc(d['toc_url'])
    if not toc: return jsonify({"status": "error"})
    return jsonify({"status": "success", "task_id": managers.downloader.start_download(d['book_name'], toc['chapters'], crawler)})

@core_bp.route('/api/download/status')
@login_required
def dl_status(): return jsonify(managers.downloader.get_status(request.args.get('task_id')))

@core_bp.route('/api/download/file')
@login_required
def dl_file():
    t = managers.downloader.get_status(request.args.get('task_id'))
    return send_from_directory(DL_DIR, t['filename'], as_attachment=True) if t else ("Not Found", 404)

@core_bp.route('/manifest.json')
def serve_manifest(): return send_file('manifest.json')
@core_bp.route('/sw.js')
def serve_sw(): return send_file('sw.js')
@core_bp.route('/static/<path:filename>')
def serve_static(filename): return send_from_directory(os.path.join(BASE_DIR, 'static'), filename)
@core_bp.route('/purecss/<path:path>')
def send_pure(path): return send_from_directory(os.path.join(BASE_DIR, 'purecss'), path)