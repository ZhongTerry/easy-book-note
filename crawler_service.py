import os
import time
import requests
import json
import logging
import sys
from dotenv import load_dotenv

# åŠ è½½é…ç½®
load_dotenv('config.env')

# =========================================================
# ğŸ›¡ï¸ æ ¸å¿ƒä¿®å¤ï¼šæ„å»ºä¸€ä¸ªâ€œå“‘å·´â€ç¯å¢ƒ
# =========================================================
# å®šä¹‰ä¸€ä¸ªåªä¼šè¿”å› None çš„ç©ºç±»ï¼Œé˜²æ­¢ MagicMock è‡ªåŠ¨ç”Ÿæˆå¯¹è±¡
class EmptyObject:
    def __getattr__(self, name):
        return None
    def __call__(self, *args, **kwargs):
        return None
    def __getitem__(self, key):
        return None
    def get(self, key, default=None):
        return default

# 1. åˆ›å»ºå‡çš„ managers
class MockManagers:
    # æ¨¡æ‹Ÿ cache
    class MockCache:
        def get(self, *args): return None  # æ ¸å¿ƒï¼šå¼ºåˆ¶æœªå‘½ä¸­ç¼“å­˜
        def set(self, *args): pass         # æ ¸å¿ƒï¼šå‡è£…å†™å…¥ç¼“å­˜ï¼Œå®é™…å•¥ä¹Ÿä¸å¹²
        def cleanup_expired(self): pass

    # æ¨¡æ‹Ÿ db
    class MockDB:
        def get_val(self, *args): return None
        def list_all(self): return {"data": {}}
    
    # æ¨¡æ‹Ÿå…¶ä»–ç»„ä»¶
    class MockGeneric:
        def __getattr__(self, name): return EmptyObject()
        def load(self, *args): return {} # è¿”å›ç©ºå­—å…¸
        def get_chapter(self, *args): return None

    # å®ä¾‹åŒ–
    cache = MockCache()
    db = MockDB()
    offline_manager = MockGeneric()
    booklist_manager = MockGeneric()
    tag_manager = MockGeneric()
    stats_manager = MockGeneric()
    history_manager = MockGeneric()
    update_manager = MockGeneric()
    role_manager = MockGeneric()

    # æ¨¡æ‹Ÿé…ç½®å˜é‡ (é˜²æ­¢æŠ¥é”™)
    USER_DATA_DIR = "/tmp"
    CACHE_DIR = "/tmp"
    DL_DIR = "/tmp"

# 2. å¼ºè¡Œæ³¨å…¥ç³»ç»Ÿæ¨¡å—
# è¿™æ · spider_core å¯¼å…¥ managers æ—¶ï¼Œæ‹¿åˆ°çš„å°±æ˜¯æˆ‘ä»¬å®šä¹‰çš„è¿™ä¸ªâ€œå“‘å·´â€å¯¹è±¡
sys.modules['managers'] = MockManagers()
sys.modules['managers.cache'] = MockManagers.cache

# =========================================================
# å¯¼å…¥çˆ¬è™«æ ¸å¿ƒ (å¿…é¡»åœ¨æ³¨å…¥ä¹‹å)
# =========================================================
from spider_core import crawler_instance as crawler, searcher

# === é…ç½®åŒº ===
MASTER_URL = os.environ.get("MASTER_URL", "https://book.ztrztr.top")
AUTH_TOKEN = os.environ.get("REMOTE_CRAWLER_TOKEN", "my-secret-token-888")
NODE_NAME = os.environ.get("NODE_NAME", "Worker-Node")

def do_work(task):
    """æ‰§è¡Œå…·ä½“ä»»åŠ¡"""
    endpoint = task['endpoint']
    payload = task['payload']
    url = payload.get('url')
    
    print(f"âš¡ [Job] æ‰§è¡Œ: {endpoint} -> {url}")
    
    result = {"status": "failed", "msg": "Unknown error"}
    
    try:
        data = None
        # å¼ºåˆ¶çˆ¬å–é€»è¾‘
        if endpoint == 'run':
            data = crawler.run(url)
        elif endpoint == 'toc':
            data = crawler.get_toc(url)
        elif endpoint == 'search':
            data = searcher.search_bing(payload.get('keyword'))
            
        if data:
            # å†æ¬¡æ£€æŸ¥æ•°æ®é‡Œæœ‰æ²¡æœ‰æ··å…¥ Mock å¯¹è±¡ (é˜²å¾¡æ€§ç¼–ç¨‹)
            # å¦‚æœæœ‰ï¼Œè¯´æ˜ spider_core é‡Œæœ‰æ¼ç½‘ä¹‹é±¼ï¼Œè¿™é‡Œå°†å…¶æ¸…æ´—ä¸ºå­—ç¬¦ä¸²
            try:
                json.dumps(data) # å°è¯•åºåˆ—åŒ–
            except TypeError:
                print("âš ï¸ æ£€æµ‹åˆ°è„æ•°æ®ï¼Œæ­£åœ¨æ¸…æ´—...")
                data = clean_data(data)

            result = {"status": "success", "data": data}
        else:
            result = {"status": "failed", "msg": "Empty data from crawler"}
            
    except Exception as e:
        print(f"âŒ ä»»åŠ¡å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        result = {"status": "error", "msg": str(e)}
        
    return result

def clean_data(obj):
    """é€’å½’æ¸…æ´—æ•°æ®ï¼ŒæŠŠæ‰€æœ‰éåŸºæœ¬ç±»å‹è½¬ä¸ºå­—ç¬¦ä¸²"""
    if isinstance(obj, dict):
        return {k: clean_data(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [clean_data(v) for v in obj]
    elif isinstance(obj, (str, int, float, bool, type(None))):
        return obj
    else:
        return str(obj) # å¼ºåˆ¶è½¬å­—ç¬¦ä¸² (å¤„ç†æ¼ç½‘çš„ Mock å¯¹è±¡)

def worker_loop():
    print(f"ğŸš€ Worker [{NODE_NAME}] å¯åŠ¨ (Pull Mode)")
    print(f"ğŸ”— è¿æ¥ Master: {MASTER_URL}")
    print(f"ğŸ›¡ï¸  ç¼“å­˜å±‚å·²å±è”½ï¼Œå…¨é‡å®æ—¶çˆ¬å–")
    
    session = requests.Session()
    session.headers.update({
        "Authorization": f"Bearer {AUTH_TOKEN}",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    })
    
    while True:
        try:
            payload = {"uuid": NODE_NAME}
            resp = session.post(f"{MASTER_URL}/api/cluster/fetch_task", json=payload, timeout=10)
            
            if resp.status_code == 403:
                print("ğŸ”’ Token é”™è¯¯")
                time.sleep(10)
                continue
            
            if resp.status_code != 200:
                print(f"âš ï¸ API å¼‚å¸¸: {resp.status_code}")
                time.sleep(5)
                continue
                
            try:
                res_json = resp.json()
            except:
                print("âš ï¸ é JSON å“åº”")
                time.sleep(5)
                continue
            
            if res_json.get('status') == 'success':
                task = res_json['task']
                crawl_result = do_work(task)
                
                # å›ä¼ ç»“æœ
                session.post(f"{MASTER_URL}/api/cluster/submit_result", json={
                    "task_id": task['id'],
                    "result": crawl_result
                })
                print(f"âœ… [Job] å®Œæˆ")
            else:
                time.sleep(1) # ç©ºé—²ç­‰å¾…
                
        except Exception as e:
            print(f"âš ï¸ ç½‘ç»œæ³¢åŠ¨: {e}")
            time.sleep(5)

if __name__ == '__main__':
    worker_loop()