# === dbserver.py (ä¿®å¤ç‰ˆ) ===
import os
from dotenv import load_dotenv # 1. å¼•å…¥è¿™ä¸ªåº“

# 2. ã€å…³é”®ã€‘å¿…é¡»åœ¨å¯¼å…¥å…¶ä»–æœ¬åœ°æ¨¡å—ï¼ˆå¦‚ routes, managersï¼‰ä¹‹å‰åŠ è½½ .env
# å¦åˆ™ routes/core_bp.py åˆå§‹åŒ–æ—¶è¯»ä¸åˆ°ç¯å¢ƒå˜é‡
load_dotenv() 
import sqlite3
from flask import Flask, render_template
from datetime import timedelta
import threading
import time
from spider_core import crawler_instance
# å¯¼å…¥é…ç½®
from shared import USER_DATA_DIR
import managers
import json
# å¯¼å…¥è“å›¾ (è¿™æ—¶å€™ .env å·²ç»åŠ è½½å¥½äº†ï¼Œcore_bp èƒ½è¯»åˆ°æ­£ç¡®çš„ SERVER)
from routes.core_bp import core_bp
from routes.admin_bp import admin_bp
from routes.pro_bp import pro_bp
# [æ–°å¢] å¼•å…¥è§£æå‡½æ•°
from spider_core import parse_chapter_id

app = Flask(__name__)

# è¿™é‡Œä¹Ÿèƒ½æ­£ç¡®è¯»åˆ° KEY äº†
app.secret_key = os.environ.get('FLASK_SECRET_KEY', 'default-unsafe-key')
app.permanent_session_lifetime = timedelta(days=30)
app.config['SESSION_COOKIE_NAME'] = 'simplenote_session'

app.register_blueprint(core_bp)
app.register_blueprint(admin_bp)
app.register_blueprint(pro_bp)

def schedule_cache_cleanup():
    time.sleep(10)
    managers.cache.cleanup_expired()
    while True:
        time.sleep(86400)
        managers.cache.cleanup_expired()

threading.Thread(target=schedule_cache_cleanup, daemon=True).start()
# === åœ¨ dbserver.py ===
import random
@app.route('/reader_m')
def reader_m():
    """å¤„ç†/reader_mè·¯ç”±ï¼Œè¿”å›reader_m.htmlæ¨¡æ¿é¡µé¢"""
    return render_template('reader_m.html')
def schedule_auto_check():
    """
    åå°çº¿ç¨‹ï¼šæ¯ 5 å°æ—¶æ£€æŸ¥ä¸€æ¬¡ 'book_updates' è¡¨çš„æ›´æ–°
    """
    time.sleep(60) # å¯åŠ¨åç­‰ä¸€ä¼šå†è·‘
    
    while True:
        print("[AutoCheck] ğŸ•’ å¼€å§‹åå°è¿½æ›´æ£€æŸ¥...")
        try:
            # 1. æ‰«æ data.sqlite (é’ˆå¯¹ä¸»æ•°æ®åº“æ¨¡å¼)
            # æˆ–è€…æ‰«æ user_data/ ä¸‹çš„æ‰€æœ‰ .sqlite æ–‡ä»¶
            db_files = [f for f in os.listdir(managers.USER_DATA_DIR) if f == 'data.sqlite']
            
            for db_f in db_files:
                db_path = os.path.join(managers.USER_DATA_DIR, db_f)
                try:
                    conn = sqlite3.connect(db_path)
                    conn.row_factory = sqlite3.Row
                    cursor = conn.cursor()
                    
                    # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                    try: cursor.execute("SELECT * FROM book_updates LIMIT 1")
                    except: 
                        conn.close()
                        continue

                    # è·å–æ‰€æœ‰è®¢é˜…
                    cursor.execute("SELECT book_key, toc_url, last_local_id FROM book_updates")
                    tasks = cursor.fetchall()
                    
                    print(f"[AutoCheck] å‘ç° {len(tasks)} ä¸ªè¿½æ›´ä»»åŠ¡ (DB: {db_f})")
                    
                    for task in tasks:
                        key = task['book_key']
                        toc_url = task['toc_url']
                        local_id = task['last_local_id']
                        
                        if not toc_url: continue
                        
                        try:
                            # === [æ ¸å¿ƒä¿®å¤] ä¿®æ­£æœ¬åœ°åŸºå‡† (åŒæ­¥ api_subscribe é€»è¾‘) ===
                            # å³ä½¿æ•°æ®åº“é‡Œè®°çš„æ˜¯ Ch 1ï¼Œä½†å¦‚æœç¼“å­˜é‡Œå·²ç»æœ‰äº† Ch 100ï¼Œ
                            # æˆ‘ä»¬åº”è¯¥ä»¥ Ch 100 ä¸ºåŸºå‡†ï¼Œé¿å…è¯¯æŠ¥ "å‘ç°æ›´æ–°"ã€‚
                            cached_toc = managers.cache.get(toc_url)
                            if cached_toc and cached_toc.get('chapters'):
                                last_chap = cached_toc['chapters'][-1]
                                cached_id = last_chap.get('id')
                                # å¦‚æœ id ä¸å­˜åœ¨æˆ–å¼‚å¸¸ï¼Œå°è¯•ä»æ ‡é¢˜è§£æ
                                if not cached_id or cached_id <= 0:
                                    cached_id = parse_chapter_id(last_chap.get('title', ''))
                                
                                # å–å¤§è€…ä½œä¸ºåŸºå‡†
                                if cached_id > local_id:
                                    # print(f"   [AutoCheck] åŸºå‡†ä¿®æ­£ {key}: DB({local_id}) -> Cache({cached_id})")
                                    local_id = cached_id

                            # === çˆ¬å–æœ€æ–°ç« èŠ‚ ===
                            # 1. è·å–ç›®å½•
                            latest_chap = crawler_instance.get_latest_chapter(toc_url, no_cache=True)
                            
                            if latest_chap:
                                remote_title = latest_chap.get('title', '')
                                
                                # [æ ¸å¿ƒä¿®å¤] ä¼˜å…ˆè§£æè‡ªç„¶åºå· (å’Œ core_bp.py ä¿æŒä¸€è‡´)
                                remote_seq = parse_chapter_id(remote_title)
                                raw_id = latest_chap.get('id', 0)
                                if isinstance(raw_id, str) and not raw_id.isdigit():
                                    raw_id = 0
                                raw_id = int(raw_id)
                                
                                # ğŸ”¥ ä¸¥æ ¼åˆ¤æ–­ï¼šåªä¿¡å°äº 10000 çš„ raw_idï¼ˆé˜²æ­¢æ•°æ®åº“ ID è¢«è¯¯è®¤ä¸ºç« èŠ‚å·ï¼‰
                                if remote_seq == -1 and 0 < raw_id < 10000:
                                     remote_seq = raw_id
                                elif remote_seq == -1:
                                     # å¦‚æœè§£æä¸å‡ºç« èŠ‚å·ï¼Œä¸” raw_id å¤ªå¤§æˆ–ä¸º 0ï¼Œç›´æ¥è·³è¿‡æ­¤æ¬¡æ£€æŸ¥
                                     print(f"   âš ï¸ [{key}] æ— æ³•è¯†åˆ«ç« èŠ‚å·: title={remote_title}, raw_id={raw_id}")
                                     continue

                                # å†³ç­–å…¥åº“ ID
                                id_to_save = remote_seq if remote_seq > 0 else raw_id
                                
                                # è°ƒè¯•æ‰“å°
                                # print(f"   [Check] {key}: Seq={remote_seq}, Raw={raw_id} -> Save={id_to_save}")

                                has_u = False
                                if id_to_save > local_id:
                                    has_u = True
                                    print(f"   ğŸ”¥ [UPDATE] {key}: æœ¬åœ°{local_id} -> è¿œç¨‹{id_to_save}")
                                
                                # æ— è®ºæœ‰æ— æ›´æ–°ï¼Œéƒ½åˆ·æ–° last_remote_idï¼Œç¡®ä¿ä¸‹æ¬¡æ¯”è¾ƒçš„åŸºç¡€æ˜¯æ­£ç¡®çš„
                                # å¦åˆ™å¦‚æœæ•°æ®åº“é‡Œå·²ç»æ˜¯é”™çš„ 3äº¿ï¼Œè¿™é‡Œä¸ update å›å»ï¼Œå°±æ°¸è¿œæ˜¯é”™çš„
                                cursor.execute("UPDATE book_updates SET last_remote_id=?, has_update=?, updated_at=CURRENT_TIMESTAMP WHERE book_key=?", 
                                             (id_to_save, 1 if has_u else 0, key))
                                conn.commit()
                            
                            # éšæœºä¼‘çœ 
                            time.sleep(random.uniform(3, 8))
                            
                        except Exception as e:
                            print(f"   âŒ æ£€æŸ¥å¤±è´¥ {key}: {e}")
                            
                    conn.close()
                except Exception as e:
                    print(f"Db Error: {e}")

        except Exception as e:
            print(f"[AutoCheck] çº¿ç¨‹å‡ºé”™: {e}")
            
        # ä¼‘çœ  5 å°æ—¶ (18000 ç§’)
        print("[AutoCheck] ä¼‘çœ  5 å°æ—¶...")
        time.sleep(18000)

# åœ¨ main ä¸­å¯åŠ¨
threading.Thread(target=schedule_auto_check, daemon=True).start()

if __name__ == '__main__':
    # ğŸ”¥ ä»ç¯å¢ƒå˜é‡è¯»å–å¼€å‘æ¨¡å¼é…ç½®
    # DEV_MODE=true æˆ– DEBUG=true å¯ç”¨å¼€å‘è€…æ¨¡å¼ï¼ˆè‡ªåŠ¨é‡è½½ï¼‰
    # é»˜è®¤ä¸ºç”Ÿäº§æ¨¡å¼ï¼ˆdebug=Falseï¼‰
    is_dev_mode = os.environ.get('DEV_MODE', '').lower() in ('true', '1', 'yes') or \
                  os.environ.get('DEBUG', '').lower() in ('true', '1', 'yes')
    
    if is_dev_mode:
        print("ğŸ”§ [Dev Mode] å¼€å‘è€…æ¨¡å¼å·²å¯ç”¨ï¼ˆæ”¯æŒä»£ç çƒ­é‡è½½ï¼‰")
        app.run(debug=True, port=5000, host='0.0.0.0')
    else:
        print("ğŸš€ [Production Mode] ç”Ÿäº§æ¨¡å¼è¿è¡Œ")
        app.run(debug=False, port=5000, host='0.0.0.0')