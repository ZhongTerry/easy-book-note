import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

class SourceWorker:
    def __init__(self):
        self.source_name = "å¿…åŽ»å°è¯´ ðŸ“š"
        self.base_url = "http://www.ibiquw.info"
        self.search_url = f"{self.base_url}/modules/article/search.php"

    def search(self, keyword):
        try:
            # æ³¨æ„ï¼šå‚æ•°é‡Œæœ‰ä¸ª action=loginï¼Œè™½ç„¶å¥‡æ€ªä½†åŠ ä¸Šä¿é™©
            params = {'searchkey': keyword, 'action': 'login'}
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
            
            resp = requests.get(self.search_url, params=params, headers=headers, timeout=10, verify=False)
            resp.encoding = 'utf-8' # æ ¹æ®metaæ ‡ç­¾æŽ¨æ–­
            
            soup = BeautifulSoup(resp.text, 'html.parser')
            results = []
            
            # è§£æžåˆ—è¡¨: .toplist ul li
            items = soup.select('.toplist ul li')
            
            for item in items:
                # ç»“æž„: p.s1 a (ä¹¦å), p.s3 (ä½œè€…)
                title_tag = item.select_one('.s1 a')
                if not title_tag: continue
                
                title = title_tag.get_text(strip=True)
                href = title_tag.get('href')
                
                author_tag = item.select_one('.s3')
                author = author_tag.get_text(strip=True) if author_tag else ""
                
                if href:
                    if not href.startswith('http'):
                        href = urljoin(self.base_url, href)
                    
                    results.append({
                        'title': title,
                        'url': href,
                        'source': self.source_name,
                        'description': f"ä½œè€…: {author}"
                    })
                if len(results) >= 5: break
                
            return results
        except Exception as e:
            return []