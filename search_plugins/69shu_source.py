from curl_cffi import requests as cffi_requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

class SourceWorker:
    def __init__(self):
        self.source_name = "69ä¹¦å§ ğŸŸ¢"
        self.base_url = "https://www.69shu.com"
        self.search_url = "https://www.69shu.com/modules/article/search.php"

    def search(self, keyword):
        try:
            # 69ä¹¦å§å¿…é¡»ç”¨ POSTï¼Œä¸”éœ€è¦ GBK ç¼–ç 
            data = {
                'searchkey': keyword.encode('gbk'),
                'searchtype': 'articlename'
            }
            
            # ä½¿ç”¨ curl_cffi æ¨¡æ‹Ÿæµè§ˆå™¨æŒ‡çº¹
            resp = cffi_requests.post(
                self.search_url, 
                data=data,
                impersonate="chrome110",
                timeout=10
            )
            
            # æ‰‹åŠ¨è§£ç  GBK
            content = resp.content.decode('gbk', errors='ignore')
            soup = BeautifulSoup(content, 'html.parser')
            
            results = []
            # 69ä¹¦å§å¦‚æœæ˜¯å”¯ä¸€ç»“æœï¼Œä¼šç›´æ¥302è·³è½¬åˆ°ç›®å½•é¡µ
            # å¦‚æœæ˜¯åˆ—è¡¨é¡µï¼Œç»“æ„é€šå¸¸æ˜¯è¡¨æ ¼
            
            # æ£€æŸ¥æ˜¯å¦ç›´æ¥è·³è½¬åˆ°äº†ç›®å½•é¡µ (åŒ…å« "ç« èŠ‚åˆ—è¡¨" å­—æ ·)
            if "ç« èŠ‚åˆ—è¡¨" in soup.title.string:
                # å½“å‰é¡µé¢å°±æ˜¯ç»“æœ
                canonical = soup.find('link', {'rel': 'canonical'})
                if canonical:
                    results.append({
                        'title': keyword, # ç®€å•å¤„ç†
                        'url': canonical['href'],
                        'source': self.source_name,
                        'description': "ç›´è¾¾ç›®å½•"
                    })
                return results

            # è§£æåˆ—è¡¨
            # 69ä¹¦å§åˆ—è¡¨é€šå¸¸åœ¨ tr ä¸­
            # è¿™é‡Œç®€å•å¤„ç†ï¼Œå¦‚æœæ²¡åŒ¹é…åˆ°ç›´æ¥è¿”å›ç©º
            
            return results
        except Exception as e:
            # print(f"[Plugin] 69Shu Error: {e}")
            return []